<1. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Audiovisual integration of rhythm in musicians and dancers. [References].
DP  - Apr 1, 2024
YR  - 2024
AU  - Nguyen, Tram
AU  - Lagace-Cusiac, Rebekka
AU  - Everling, J. Celina
AU  - Henry, Molly J
AU  - Grahn, Jessica A
SO  - Attention, Perception, & Psychophysics. 2024, pp. No Pagination Specified. 
MO  - Apr
IS  - 1943-3921
IT  - 1943-393X
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Music training is associated with better beat processing in the auditory modality. However, it is unknown how rhythmic training that emphasizes visual rhythms, such as dance training, might affect beat processing, nor whether training effects in general are modality specific. Here we examined how music and dance training interacted with modality during audiovisual integration and synchronization to auditory and visual isochronous sequences. In two experiments, musicians, dancers, and controls completed an audiovisual integration task and an audiovisual target-distractor synchronization task using dynamic visual stimuli (a bouncing figure). The groups performed similarly on the audiovisual integration tasks (Experiments 1 and 2). However, in the finger-tapping synchronization task (Experiment 1), musicians were more influenced by auditory distractors when synchronizing to visual sequences, while dancers were more influenced by visual distractors when synchronizing to auditory sequences. When participants synchronized with whole-body movements instead of finger-tapping (Experiment 2), all groups were more influenced by the visual distractor than the auditory distractor. Taken together, this study highlights how training is associated with audiovisual processing, and how different types of visual rhythmic stimuli and different movements alter beat perception and production outcome measures. Implications for the modality appropriateness hypothesis are discussed. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
DO  - https://dx.doi.org/10.3758/s13414-024-02874-x
JN  - Attention, Perception, & Psychophysics
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc23&DO=10.3758%2fs13414-024-02874-x

<2. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Linking the spatial dimension to the timing control of rhythmic movements.DP  - 2023
YR  - 2023
LG  - English
AU  - Kroger, Carolyn
SO  - Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.84,(6-B), 2023, pp. No Pagination Specified. 
IS  - 0419-4217
IB  - 979-8358494527
PT  - Dissertation Abstract
AB  - Rhythmically timed movements are integral to a wide range of human behaviors, including the production of fluent speech, music performance, dance, and sports, to name a few. Deficits in the timing of rhythmic movements have been observed in numerous neurological conditions, which can be devastating for an individual's quality of life. One common method to investigate mechanisms underpinning the timing of rhythmic actions is a finger tapping task in which individuals synchronize finger taps with a series of tones that establish a target inter-tap interval (ITI) and then continue to produce the target interval after the tones stop. The data of interest in these studies have almost exclusively consisted of the time series of tap onsets and associated sequence of ITIs. Because all movements are inherently spatiotemporal, the thesis investigated herein is that our understanding of timing processes is incomplete because previous work ignores the contributions of spatial elements of an individual's movements to their timing control. The experiments reported here fill this gap by using continuous motion tracking to measure the spatiotemporal dynamics of paced and unpaced rhythmic finger tapping and by considering the relation between spatiotemporal measures and timing accuracy and precision. Five experiments tested a series of hypotheses about contributions of spatiotemporal factors to the timing control of rhythmic movements. Experiment 1 tested a preferred velocity hypothesis that integrates amplitude and tempo for unpaced tapping. Participants completed unpaced tapping tasks that separately assessed preferred movement amplitude (finger height) and tempo (Mean ITI). In support of this hypothesis, participants produced similar amplitudes and tempi regardless of instructions for either preferred amplitude or tempo. Experiments 2 and 3 tested an amplitude control hypothesis for paced tapping where participants matched a wide range of target ITIs. Consistent with this hypothesis, individuals decreased tap amplitude with shorter target ITIs and variability in amplitudes predicted variability in ITIs. Further supporting this hypothesis, forcing participants to produce low and high amplitudes during paced tapping interfered with timing accuracy and precision in a manner consistent with amplitude as a parameter in timing control. The preferred velocity hypothesis was further supported by results showing that timing was less variable for conditions where participants tapped at target amplitudes and tempi that, in combination, were closer to their preferred velocity. Experiment 4 extended this line of work to timing control of tapping at slow tempi (near the temporal boundary where perceived rhythm breaks down). Of primary interest was a dwell time hypothesis, which proposes that at slow target ITI when amplitude cannot be increased further to lengthen intervals, participants increase dwell time (how long their finger rests on the table) to produce longer ITIs. Providing initial support for this hypothesis, participants kept tap amplitude constant and increased tap dwell time to produce longer ITIs. At the slowest target ITI, a bimodal distribution in tap dwell times also was observed, reflecting individual differences in dwell time strategy where some participants kept a constant proportion of dwell time to target ITI, while others increased the proportion of dwell time at slower tempi (longer ITIs). As a follow-up, Experiment 5 manipulated tap dwell time during paced tapping at comfortable and very slow tempi (ITIs). Participants successfully lengthened or shortened their dwell time at the slow ITI, regardless of their preferred dwell time. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
JN  - Dissertation Abstracts International: Section B: The Sciences and Engineering
VO  - 84
IP  - 6-B
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&AN=2023-38657-264

<3. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Turn that music down! Affective musical bursts cause an auditory dominance in children recognizing bodily emotions. [References].
DP  - Jun 2023
YR  - 2023
LG  - English
AU  - Ross, Paddy
AU  - Williams, Ella
AU  - Herbert, Gemma
AU  - Manning, Laura
AU  - Lee, Becca
SO  - Journal of Experimental Child Psychology. Vol.230, 2023, pp. 1-8.  ArtID 105632.
MO  - Jun
IS  - 0022-0965
IT  - 1096-0457
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Previous work has shown that different sensory channels are prioritized across the life course, with children preferentially responding to auditory information. The aim of the current study was to investigate whether the mechanism that drives this auditory dominance in children occurs at the level of encoding (overshadowing) or when the information is integrated to form a response (response competition). Given that response competition is dependent on a modality integration attempt, a combination of stimuli that could not be integrated was used so that if children's auditory dominance persisted, this would provide evidence for the overshadowing over the response competition mechanism. Younger children (<=7 years), older children (8-11 years), and adults (18+ years) were asked to recognize the emotion (happy or fearful) in either nonvocal auditory musical emotional bursts or human visual bodily expressions of emotion in three conditions: unimodal, congruent bimodal, and incongruent bimodal. We found that children performed significantly worse at recognizing emotional bodies when they heard (and were told to ignore) musical emotional bursts. This provides the first evidence for auditory dominance in both younger and older children when presented with modally incongruent emotional stimuli. The continued presence of auditory dominance, despite the lack of modality integration, was taken as supportive evidence for the overshadowing explanation. These findings are discussed in relation to educational considerations, and future sensory dominance investigations and models are proposed. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1016/j.jecp.2023.105632
JN  - Journal of Experimental Child Psychology
VO  - 230
PG  - 1-8
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1016%2fj.jecp.2023.105632

<4. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - The effect of auditory device, onset of hearing loss, and chronologic age on music perception and appreciation in adult listeners.DP  - 2022
YR  - 2022
LG  - English
AU  - Fowler, Stephanie L
SO  - Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.83,(8-B), 2022, pp. No Pagination Specified. 
IS  - 0419-4217
IB  - 979-8759946915
PT  - Dissertation Abstract
AB  - Adults with hearing loss perceive music through a degraded auditory filter initially designed for enhanced speech perception. Although they exhibit difficulty perceiving musical characteristics in research and clinic, adults with hearing loss do not exhibit a consistent decrease in appreciation of musical activities. Poor perception, in general, does not result in lower appreciation of music. Previous studies have assessed the perceptual skills of cochlear implant (CI) listeners, hearing aid (HA) listeners, and typical hearing (TH) adults, as well as the subjective music experiences of these groups. To date, few studies have investigated these groups on both subjective and objective measures together; assessed the distinct music experiences of pre- and postlingual adults; or determined how chronologic age influences music experiences.This project aims to understand the differences in objective music perception and self-reported music experiences among (a) TH, CI, and HA listeners; (b) pre-lingual (i.e., onset of deafness before age three) and post-lingual (i.e., onset of deafness after age three) CI listeners; and (c) younger compared to older (>= 60 years) adult CI listeners.Sixty participants 18 years or older were grouped according to device status, onset of deafness, and age. Participants with a bimodal configuration used only one of their devices during testing. Demographic and audiologic characteristics were obtained from an ad hoc survey. The Clinical Assessment of Music Perception (CAMP) assessed behavioral perception of pitch, familiar melody, and instrument identification. In addition, one subtest of the Profile of Musical Skills (PROMS) assessed behavioral perception of unfamiliar melodies. These four subtests comprise the objective evaluation of music perception. The Music-Related Quality of Life (MuRQoL) assessed subjective exposure to musical characteristics and situations and their relative importance. Two domains (Music Abilities and Music Importance) comprise the subjective evaluation of music appreciation. Participants with TH discriminated pitches, recognized familiar melodies, recognized instruments, and discriminated unfamiliar melodies better than postlingual CI listeners, but not those with HAs. CI listeners stratified by age at diagnosis of hearing loss and chronologic age performed in similar ways on all objective measures, and large variability was present. Overall, all groups with and without hearing loss reported similar levels of music importance. Across all participants grouped together, objective and subjective measures were correlated, such that individuals who scored well on objective measures also tended to self-report higher music abilities, in general. Furthermore, across all participants grouped together, subjective self-report of music skills tended to correlate with objective performance on that specific skill. However, when examined within each group, objective measures largely did not correlate with subjective measures.Because auditory devices have thus far been optimized for speech, research regarding the musical experiences of those who use them is extremely limited. However, participants in this study report that music remains important in their lives and that hearing loss and auditory devices diminish the perceptual characteristics necessary for access to typical music experiences. There remains a need to develop clinically feasible measures of real-world musical experiences and develop interventions to improve access to music. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
JN  - Dissertation Abstracts International: Section B: The Sciences and Engineering
VO  - 83
IP  - 8-B
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc21&AN=2022-45359-294

<5. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Use of explicit priming to phenotype absolute pitch ability. [References].
DP  - Sep 14, 2022
YR  - 2022
LG  - English
AU  - Bairnsfather, Jane E
AU  - Osborne, Margaret S
AU  - Martin, Catherine
AU  - Mosing, Miriam A
AU  - Wilson, Sarah J
SO  - PLoS ONE. Vol.17,(9), 2022, ArtID e0273828.
MO  - Sep
IT  - 1932-6203
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Musicians with absolute pitch (AP) can name the pitch of a musical note in isolation. Expression of this unusual ability is thought to be influenced by heritability, early music training and current practice. However, our understanding of factors shaping its expression is hampered by testing and scoring methods that treat AP as dichotomous. These fail to capture the observed variability in pitch-naming accuracy among reported AP possessors. The aim of this study was to trial a novel explicit priming paradigm to explore phenotypic variability of AP. Thirty-five musically experienced individuals (Mage = 29 years, range 18-68; 14 males) with varying AP ability completed a standard AP task and the explicit priming AP task. Results showed: 1) phenotypic variability of AP ability, including high-accuracy AP, heterogeneous intermediate performers, and chance-level performers; 2) intermediate performance profiles that were either reliant on or independent of relative pitch strategies, as identified by the priming task; and 3) the emergence of a bimodal distribution of AP performance when adopting scoring criteria that assign credit to semitone errors. These findings show the importance of methods in studying behavioural traits, and are a key step towards identifying AP phenotypes. Replication of our results in larger samples will further establish the usefulness of this priming paradigm in AP research. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
DO  - https://dx.doi.org/10.1371/journal.pone.0273828
JN  - PLoS ONE
VO  - 17
IP  - 9
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc21&DO=10.1371%2fjournal.pone.0273828

<6. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Multimodal expression in communicative functions, gestures, vocalizations, and the contribution of early musicality. [References].
DP  - 2022
YR  - 2022
LG  - English
AU  - Rodriguez, Fernando G
SO  - Espanol, Silvia [Ed]; Martinez, Mauricio [Ed]; Rodriguez, Fernando G [Ed]. (2022). Moving and interacting in infancy and early childhood: An embodied, intersubjective, and multimodal approach to the interpersonal world. (pp. 247-283). x, 330pp. Cham, Switzerland: Springer Nature Switzerland AG; Switzerland. 
IB  - 978-3-031-08922-0 (Hardcover); 978-3-031-08923-7 (Digital (undefined format))
PT  - Book
PT  - Edited Book
AB  - The communicative functions with which infants and pregrammatical speaking children use signs to interact with others have been the subject of different classifications, usually concentrated in one modality (gesture, word) or in bimodal combinations of gesture and word, or oriented by a particular criterion (for example, some were conceived thinking of types of signs, others of the illocutionary acts of utterances, etc.). With an integrative aim, we propose a classification of the communicative functions of oral, gestural, and combined modalities, also suitable to include signs of other types and especially designed to deal with pregrammatical expressive resources. The system of categories is forged in attention both to the structural scheme of the communicative act, bearing in mind its actors, roles, and component elements, and to the motives or intentions that lead pregrammatical infants and children to interact with others through behaviors performed, purposively, for the other to decode. This double consideration, together with the longitudinal recording of a single case during the period of first word combinations, allowed both to include categories usually omitted in classifications for competent speakers (adults, older children) and to exclude others that still require the acquisition of prior enabling cognitive skills. Three new categories are also posited, two of them liminal to the communication phenomenon, linked to musicality and multimodality, which allow conceiving the development of the child's semiosis as a continuity between precommunicative and later communicative dyadic behavioral skills. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
DO  - https://dx.doi.org/10.1007/978-3-031-08923-7_8
PG  - 247-283
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc21&DO=10.1007%2f978-3-031-08923-7_8

<7. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Moving and interacting in infancy and early childhood: An embodied, intersubjective, and multimodal approach to the interpersonal world.DP  - 2022
YR  - 2022
LG  - English
AU  - Espanol, Silvia [Ed]
AU  - Martinez, Mauricio [Ed]
AU  - Rodriguez, Fernando G [Ed]
SO  - (2022). Moving and interacting in infancy and early childhood: An embodied, intersubjective, and multimodal approach to the interpersonal world. x, 330pp. Cham, Switzerland: Springer Nature Switzerland AG; Switzerland. 
IB  - 978-3-031-08922-0 (Hardcover); 978-3-031-08923-7 (Digital (undefined format))
PT  - Book
PT  - Edited Book
AB  - This book introduces studies on infant and early childhood development that are in a permanent dialogue with the psychology of music, the philosophy of mind, and human movement studies. They are based on an innovative framework that combines embodied cognition, the multimodal approach to child development, and the second-person perspective in social cognition. This frame of reference allows authors to revisit relevant topics in developmental psychology, such as adult-infant interactions; early intersubjective experiences; the development of perceptual, verbal and gestural communication skills; as well as the complexity of play in infancy and early childhood. In the field of infancy and early childhood studies, the three viewpoints brought together in this volume had a clear innovative impact. Embodied psychology showed the body to be the primary agent in the interactions that shape the infant's psyche. The second-person perspective exhibited the direct, transparent, I-Thou contact involved in the first patterns of reciprocity between adult and infant, and the multimodal theory of perceptual development revealed an infant immersed in a multisensory environment conveying information to all perceptual systems as a unified experience. The studies presented in this volume combine these three viewpoints and link them through the use of analytical tools and concepts from the temporal arts (music and dance). This way of conducting empirical research on some central topics in early infancy led to an aesthetic conception of development that emphasizes bodily experience, temporal affects and their intertwining with symbolic capacities. Moving and Interacting in Infancy and Early Childhood: An Embodied, Intersubjective, and Multimodal Approach to the Interpersonal World will provide innovative tools for developmental and cognitive psychologists studying the development of early socio-cognitive skills in infants and young children, and will also serve as a rich source of information for researchers and practitioners in other fields, such as education and nursing, who can benefit from cutting-edge knowledge in developmental sciences. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
DO  - https://dx.doi.org/10.1007/978-3-031-08923-7
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc21&DO=10.1007%2f978-3-031-08923-7

<8. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Searching for the key to musical scale-sensitivity through rhythm, speech, and pitch.DP  - 2022
YR  - 2022
LG  - English
AU  - Ho, Joselyn
SO  - Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.83,(4-B), 2022, pp. No Pagination Specified. 
IS  - 0419-4217
IB  - 979-8460475278
PT  - Dissertation Abstract
AB  - This dissertation investigates the sources of musical scale-sensitivity, or the sensitivity to musical mode. In Chapter 1, I introduce the concept of scale-sensitivity, the tone-scramble "3-task" paradigm that can be used to measure this skill, and the open questions surrounding the bimodal distribution of scale-sensitivity in the general population. In Chapter 2, I investigate whether the temporal structure of tone-scramble stimuli influences scale-sensitivity. By manipulating the speed and the grouping of tones in the stimuli, I find that inserting regular, brief rests into the tone sequences heightens sensitivity to musical mode, and that specific note sequences can strongly bias listeners to perceive a stimulus as one type over another. In Chapter 3, I investigate whether scale-sensitivity is related to sensitivity to speech prosody. I find evidence that scale-sensitivity and speech sensitivity may depend on shared processing resources that are largely unaffected by musical training. In Chapter 4, I explore the relationship between scale-sensitivity and pitch-difference threshold by testing listeners in variations of a pitch comparison task. I find that having a pitch-difference threshold below 50 cents on a roved pitch comparison task is required to achieve high scale-sensitivity. Finally, in Chapter 5, I discuss the implications of these findings on music and emotion perception and present next steps in continuing to understand the source of scale-sensitivity. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
JN  - Dissertation Abstracts International: Section B: The Sciences and Engineering
VO  - 83
IP  - 4-B
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc21&AN=2022-13248-088

<9. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - The benefits of preserving residual hearing following cochlear implantation: A systematic review. [References].
DP  - Aug 2021
YR  - 2021
LG  - English
AU  - Schaefer, Simone
AU  - Sahwan, Maryam
AU  - Metryka, Aleksandra
AU  - Kluk, Karolina
AU  - Bruce, Iain A
SO  - International Journal of Audiology. Vol.60,(8), 2021, pp. 561-577. 
MO  - Aug
IS  - 1499-2027
IT  - 1708-8186
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Objective: Systematically review the current literature for evidence on the "real-life" benefits of hearing preservation cochlear implantation (HPCI) for children and adults. Design: Systematic search of Pubmed, MEDLINE, EMBASE, CINHAL and Cochrane Library for MesH terms hearing preservation and cochlear implantation. Inclusion criteria were the "real-life" benefit of HPCI i.e. other than pre- and post-operative pure tone thresholds. Exclusion criteria were non-English language, conference abstracts, reviews and animal and cadaveric studies. Risk of bias was assessed using the Evidence Project Tool. Study sample: 37 studies that matched criteria for review with 8/37 including children and 29/37 including adults. Results: HPCI was associated with better speech perception in noise in 18/26 papers and better music perception in 4/5 papers. There was no significant benefit reported in speech perception in quiet (14/20 papers) or binaural cues (3/4 papers), nor was there convincing evidence of HPCI outperforming bimodal users (5/7 papers). QoL scores were high amongst HPCI patients (2/2 papers). Interpretation of findings was hindered by small study groups and significant heterogeneity in various parameters. Conclusion: Current literature on the "real-life" benefit of HPCI, although limited, supports the existence of meaningful benefit, especially in speech perception in noise and music perception. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1080/14992027.2020.1863484
JN  - International Journal of Audiology
VO  - 60
IP  - 8
PG  - 561-577
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1080%2f14992027.2020.1863484

<10. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Bimodal benefit for music perception: Effect of acoustic bandwidth. [References].
DP  - Apr 2021
YR  - 2021
LG  - English
AU  - D'Onofrio, Kristen L
AU  - Gifford, Rene H
SO  - Journal of Speech, Language, and Hearing Research. Vol.64,(4), 2021, pp. 1341-1353. 
MO  - Apr
IS  - 1092-4388
IT  - 1558-9102
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Purpose: The challenges associated with cochlear implant (Cl)-mediated listening are well documented; however, they can be mitigated through the provision of aided acoustic hearing in the contralateral ear-a configuration termed bimodal hearing. This study extends previous literature to examine the effect of acoustic bandwidth in the non-CI ear for music perception. The primary aim was to determine the minimum and optimum acoustic bandwidth necessary to obtain bimodal benefit for music perception and speech perception. Method: Participants included 12 adult bimodal listeners and 12 adult control listeners with normal hearing. Music perception was assessed via measures of timbre perception and subjective sound quality of real-world music samples. Speech perception was assessed via monosyllabic word recognition in quiet. Acoustic stimuli were presented to the non-CI ear in the following filter conditions: < 125, < 250, < 500, and < 750 Hz, and wideband (full bandwidth). Results: Generally, performance for all stimuli improved with increasing acoustic bandwidth; however, the bandwidth that is both minimally and optimally beneficial may be dependent upon stimulus type. On average, music sound quality required wideband amplification, whereas speech recognition with a male talker in quiet required a narrower acoustic bandwidth (< 250 Hz) for significant benefit. Still, average speech recognition performance continued to improve with increasing bandwidth. Conclusion: Further research is warranted to examine optimal acoustic bandwidth for additional stimulus types; however, these findings indicate that wideband amplification is most appropriate for speech and music perception in individuals with bimodal hearing. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1044/2020_JSLHR-20-00390
JN  - Journal of Speech, Language, and Hearing Research
VO  - 64
IP  - 4
PG  - 1341-1353
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1044%2f2020_JSLHR-20-00390

<11. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Melodic interval perception with acoustic and electric hearing in bimodal and single-sided deaf cochlear implant listeners. [References].
DP  - Feb 2021
YR  - 2021
LG  - English
AU  - Spitzer, Emily R
AU  - Galvin, John J III
AU  - Friedmann, David R
AU  - Landsberger, David M
SO  - Hearing Research. Vol.400, 2021, ArtID 108136.
MO  - Feb
IS  - 0378-5955
IT  - 1878-5891
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Two notes sounded sequentially elicit melodic intervals and contours that form the basis of melody. Many previous studies have characterized pitch perception in cochlear implant (CI) users to be poor which may be due to the limited spectro-temporal resolution and/or spectral warping with electric hearing compared to acoustic hearing (AH). Poor pitch perception in CIs has been shown to distort melodic interval perception. To characterize this interval distortion, we recruited CI users with either normal (single sided deafness, SSD) or limited (bimodal) AH in the non-implanted ear. The contralateral AH allowed for a stable reference with which to compare melodic interval perception in the CI ear, within the same listener. Melodic interval perception was compared across acoustic and electric hearing in 9 CI listeners (4 bimodal and 5 SSD). Participants were asked to rank the size of a probe interval presented to the CI ear to a reference interval presented to the contralateral AH ear using a method of constant stimuli. Ipsilateral interval ranking was also measured within the AH ear to ensure that listeners understood the task and that interval ranking was stable and accurate within AH. Stimuli were delivered to the AH ear via headphones and to the CI ear via direct audio input (DAI) to participants' clinical processors. During testing, a reference and probe interval was presented and participants indicated which was larger. Ten comparisons for each reference-probe combination were presented. Psychometric functions were fit to the data to determine the probe interval size that matched the reference interval. Across all AH reference intervals, the mean matched CI interval was 1.74 times larger than the AH reference. However, there was great inter-subject variability. For some participants, CI interval distortion varied across different reference AH intervals; for others, CI interval distortion was constant. Within the AH ear, ipsilateral interval ranking was accurate, ensuring that participants understood the task. No significant differences in the patterns of results were observed between bimodal and SSD CI users. The present data show that much larger intervals were needed with the CI to match contralateral AH reference intervals. As such, input melodic patterns are likely to be perceived as frequency compressed and/or warped with electric hearing, with less variation among notes in the pattern. The high inter-subject variability in CI interval distortion suggests that CI signal processing should be optimized for individual CI users. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1016/j.heares.2020.108136
JN  - Hearing Research
VO  - 400
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc20&DO=10.1016%2fj.heares.2020.108136

<12. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Rhythm pattern discrimination by primary school students. [References].
DP  - Oct 2021
YR  - 2021
LG  - English
AU  - Dura, Jorge Antonio
AU  - Tejada, Jesus
SO  - Research Studies in Music Education. Vol.43,(3), 2021, pp. 528-547. 
MO  - Oct
IS  - 1321-103X
IT  - 1834-5530
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Ascertaining the most effective modes of presenting rhythmic information to students is extremely important in order to facilitate rhythm training. This study examines the effects of different bimodal presentations of rhythmic information on the discrimination of rhythm patterns by primary school students. A 2 x 2 factorial design was conducted with two variables-audiovisual and audio-textual-each using two levels (static and dynamic). Four experimental conditions were designed: (1) static audiovisual, (2) dynamic audiovisual, (3) static audio-textual and (4) dynamic audio-textual. Data were collected by administering a rhythmic discrimination test to intact classes in second grade (N = 83; 40 boys and 43 girls; 7-8 years old; medium socio-economic level) at two public primary schools from Comunitat Valenciana, Spain. Fourteen rhythmic patterns were presented to each group in each condition. Each pattern was played three consecutive times. The test consisted of comparing the third presentation of each pattern to the first two presentations - thereby exposing the sample pattern-and deciding whether the third was the same or not. The following covariates were measured: age, previous rhythmic skills, musicians in the family environment, out-of-school music studies and grades earned in music school classes during the previous year. The test scores show significant statistical differences between dynamic audiovisual and static audio-textual (g = 1.25), as well as between dynamic audio-textual and static audio-textual (g = .90). Furthermore, the audiovisual presentation mode was superior to its audio-textual counterpart (g = .46) and the findings showed that the dynamic presentations were more effective than the static ones (g = .69). The implications for teaching and learning rhythm are discussed. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
DO  - https://dx.doi.org/10.1177/1321103X19869056
JN  - Research Studies in Music Education
VO  - 43
IP  - 3
PG  - 528-547
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc20&DO=10.1177%2f1321103X19869056

<13. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Neural and behavioral evidence for vibrotactile beat perception and bimodal enhancement. [References].
DP  - Apr 2021
YR  - 2021
LG  - English
AU  - Gilmore, Sean A
AU  - Russo, Frank A
SO  - Journal of Cognitive Neuroscience. Vol.33,(4), 2021, pp. 635-650. 
MO  - Apr
IS  - 0898-929X
IT  - 1530-8898
PT  - Journal
PT  - Peer Reviewed Journal
AB  - The ability to synchronize movements to a rhythmic stimulus, referred to as sensorimotor synchronization (SMS), is a behavioral measure of beat perception. Although SMS is generally superior when rhythms are presented in the auditory modality, recent research has demonstrated near-equivalent SMS for vibrotactile presentations of isochronous rhythms [Ammirante, P., Patel, A. D., & Russo, F. A. Synchronizing to auditory and tactile metronomes: A test of the auditory-motor enhancement hypothesis. Psychonomic Bulletin & Review, 23, 1882-1890, 2016]. The current study aimed to replicate and extend this study by incorporating a neural measure of beat perception. Nonmusicians were asked to tap to rhythms or to listen passively while EEG data were collected. Rhythmic complexity (isochronous, nonisochronous) and presentation modality (auditory, vibrotactile, bimodal) were fully crossed. Tapping data were consistent with those observed by Ammirante et al. (2016), revealing near-equivalent SMS for isochronous rhythms across modality conditions and a drop-off in SMS for nonisochronous rhythms, especially in the vibrotactile condition. EEG data revealed a greater degree of neural entrainment for isochronous compared to nonisochronous trials as well as for auditory and bimodal compared to vibrotactile trials. These findings led us to three main conclusions. First, isochronous rhythms lead to higher levels of beat perception than nonisochronous rhythms across modalities. Second, beat perception is generally enhanced for auditory presentations of rhythm but still possible under vibrotactile presentation conditions. Finally, exploratory analysis of neural entrainment at harmonic frequencies suggests that beat perception may be enhanced for bimodal presentations of rhythm. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1162/jocn_a_01673
JN  - Journal of Cognitive Neuroscience
VO  - 33
IP  - 4
PG  - 635-650
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc20&DO=10.1162%2fjocn_a_01673

<14. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Auditory aversion in absolute pitch possessors. [References].
DP  - Feb 2021
YR  - 2021
LG  - English
AU  - Rogenmoser, Lars
AU  - Li, H. Charles
AU  - Jancke, Lutz
AU  - Schlaug, Gottfried
SO  - Cortex: A Journal Devoted to the Study of the Nervous System and Behavior. Vol.135, 2021, pp. 285-297. 
MO  - Feb
IS  - 0010-9452
IT  - 1973-8102
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Absolute pitch (AP) refers to the ability of identifying the pitch of a given tone without reliance on any reference pitch. The downside of possessing AP may be the experience of disturbance when exposed to out-of-tune tones. Here, we investigated this so-far unexplored phenomenon in AP, which we refer to as auditory aversion. Electroencephalography (EEG) was recorded in a sample of AP possessors and matched control musicians without AP while letting them perform a task underlying a so-called affective priming paradigm: Participants judged valenced pictures preceded by musical primes as quickly and accurately as possible. The primes were bimodal, presented as tones in combination with visual notations that either matched or mismatched the actually presented tone. Both samples performed better in judging unpleasant pictures over pleasant ones. In comparison with the control musicians, the AP possessors revealed a more profound discrepancy between the two valence conditions, and their EEG revealed later peaks at around 200 ms (P200) after prime onset. Their performance dropped when responding to pleasant pictures preceded by incongruent primes, especially when mistuned by one semitone. This interference was also reflected in an EEG deflection at around 400 ms (N400) after picture onset, preceding the behavior responses. These findings suggest that AP possessors process mistuned musical stimuli and pleasant pictures as affectively unrelated with each other, supporting an aversion towards out-of-tune tones in AP possessors. The longer prime-related P200 latencies exhibited by AP possessors suggest a delay in integrating musical stimuli, underlying an altered affinity towards pitch-label associations. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1016/j.cortex.2020.11.020
JN  - Cortex: A Journal Devoted to the Study of the Nervous System and Behavior
VO  - 135
PG  - 285-297
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc20&DO=10.1016%2fj.cortex.2020.11.020

<15. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Does musical interaction in a jazz duet modulate peripersonal space? [References].
DP  - Jul 2021
YR  - 2021
LG  - English
AU  - Dell'Anna, A
AU  - Rosso, M
AU  - Bruno, V
AU  - Garbarini, F
AU  - Leman, M
AU  - Berti, A
SO  - Psychological Research. Vol.85,(5), 2021, pp. 2107-2118. 
MO  - Jul
IS  - 0340-0727
IT  - 1430-2772
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Researchers have widely studied peripersonal space (the space within reach) in the last 20 years with a focus on its plasticity following the use of tools and, more recently, social interactions. Ensemble music is a sophisticated joint action that is typically explored in its temporal rather than spatial dimensions, even within embodied approaches. We, therefore, devised a new paradigm in which two musicians could perform a jazz standard either in a cooperative (correct harmony) or uncooperative (incorrect harmony) condition, under the hypothesis that their peripersonal spaces are modulated by the interaction. We exploited a well-established audio-tactile integration task as a proxy for such a space. After the performances, we measured reaction times to tactile stimuli on the subjects' right hand and auditory stimuli delivered at two different distances, (next to the subject and next to the partner). Considering previous literature's evidence that integration of two different stimuli (e.g. a tactile and an auditory stimulus) is faster in near space compared to far space, we predicted that a cooperative interaction would have extended the peripersonal space of the musicians towards their partner, facilitating reaction times to bimodal stimuli in both spaces. Surprisingly, we obtained complementary results in terms of an increase of reaction times to tactile-auditory near stimuli, but only following the uncooperative condition. We interpret this finding as a suppression of the subject's peripersonal space or as a withdrawal from the uncooperative partner. Subjective reports and correlations between these reports and reaction times comply with that interpretation. Finally, we determined an overall better multisensory integration competence in musicians compared to non-musicians tested in the same task. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1007/s00426-020-01365-6
JN  - Psychological Research
VO  - 85
IP  - 5
PG  - 2107-2118
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc19&DO=10.1007%2fs00426-020-01365-6

<16. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Music training for children with sensorineural hearing loss improves speech-in-noise perception. [References].
DP  - Jun 2020
YR  - 2020
LG  - English
AU  - Lo, Chi Yhun
AU  - Looi, Valerie
AU  - Thompson, William Forde
AU  - McMahon, Catherine M
SO  - Journal of Speech, Language, and Hearing Research. Vol.63,(6), 2020, pp. 1990-2015. 
MO  - Jun
IS  - 1092-4388
IT  - 1558-9102
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Purpose: A growing body of evidence suggests that longterm music training provides benefits to auditory abilities for typical-hearing adults and children. The purpose of this study was to evaluate how music training may provide perceptual benefits (such as speech-in-noise, spectral resolution, and prosody) for children with hearing loss. Method: Fourteen children aged 6-9 years with prelingual sensorineural hearing loss using bilateral cochlear implants, bilateral hearing aids, or bimodal configuration participated in a 12-week music training program, with nine participants completing the full testing requirements of the music training. Activities included weekly group-based music therapy and take-home music apps three times a week. The design was a pseudorandomized, longitudinal study (half the cohort was wait-listed, initially serving as a passive control group prior to music training). The test battery consisted of tasks related to music perception, music appreciation, and speech perception. As a comparison, 16 age-matched children with typical hearing also completed this test battery, but without participation in the music training. Results: There were no changes for any outcomes for the passive control group. After music training, perception of speech-in-noise, question/statement prosody, musical timbre, and spectral resolution improved significantly, as did measures of music appreciation. There were no benefits for emotional prosody or pitch perception. Conclusion: The findings suggest even a modest amount of music training has benefits for music and speech outcomes. These preliminary results provide further evidence that music training is a suitable complementary means of habilitation to improve the outcomes for children with hearing loss. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1044/2020_JSLHR-19-00391
JN  - Journal of Speech, Language, and Hearing Research
VO  - 63
IP  - 6
PG  - 1990-2015
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc19&DO=10.1044%2f2020_JSLHR-19-00391

<17. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - The perception of the stereo effect in bilateral and bimodal cochlear implant users and its contribution to music enjoyment. [References].
DP  - Jul 6, 2020
YR  - 2020
LG  - English
AU  - Buechner, Andreas
AU  - Krueger, Benjamin
AU  - Klawitter, Silke
AU  - Zimmermann, Denise
AU  - Fredelake, Stefan
AU  - Holube, Inga
SO  - PLoS ONE. Vol.15,(7), 2020, ArtID e0235435.
MO  - Jul
IT  - 1932-6203
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Objectives: In this clinical study, stereo perception of music samples and its contribution to music enjoyment in CI users is investigated. It is studied in free field as well as direct audio presentation. Methods: 20 bilateral and 9 bimodal CI users performed stereo detection tests and music enjoyment ratings. Music was presented either in mono or in stereo in free field or with direct audio presentation. Stereo detection was assessed with a 3-AFC paradigm. Music enjoyment was studied with scale ratings. Results: For bilateral CI users, stereo detection increased from 52% correct in free field to 86% with direct audio presentation. Increased music enjoyment with improved stereo detection was obtained. Bimodal CI users could not identify stereo sounds. Music enjoyment did not increase for stereo presentations in bimodal subjects. Discussion: For bilateral CI users, improved stereo detection might increase music enjoyment with direct audio presentation, which is likely due to bypassing the room acoustics. In bimodal CI users, no clear improvement was found, which is likely attributed due to the different hearing losses and therefore individually different interaural frequency overlaps between the hearing aid and the cochlear implant. Conclusion: Direct audio presentation is an efficient method to improve music enjoyment in bilateral CI users. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1371/journal.pone.0235435
JN  - PLoS ONE
VO  - 15
IP  - 7
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc19&DO=10.1371%2fjournal.pone.0235435

<18. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Multimodal sensory integration: Diminishing returns in rhythmic synchronization. [References].
DP  - Oct 2020
YR  - 2020
LG  - English
AU  - Johnson, Vinith
AU  - Hsu, Wan-Yu
AU  - Ostrand, Avery E
AU  - Gazzaley, Adam
AU  - Zanto, Theodore P
SO  - Journal of Experimental Psychology: Human Perception and Performance. Vol.46,(10), 2020, pp. 1077-1087. 
MO  - Oct
IS  - 0096-1523
IT  - 1939-1277
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Synchronizing movements with events in the surrounding environment is a ubiquitous aspect of behavior. Experiments studying multimodal integration and rhythmic synchronization tend to focus on how bimodal (e.g., audio-visual) stimuli enhances synchronization performance (i.e., reduced variability) compared with synchronization with its unimodal constituents. As such, it is unclear whether trimodal (i.e., audio-visual-tactile) stimuli may yield additional performance benefits. To address this, we developed a multimodal sensorimotor synchronization assessment that incorporates audio, visual, and vibrotactile stimuli. Results replicate performance improvements with bimodal compared with unimodal stimuli. However, trimodal stimuli yields less, or in some cases no advantage compared with bimodal stimuli. These results demonstrate that in this case, increasing the amount of sensory information beyond bimodal stimuli yields little or no additional performance benefits. (PsycInfo Database Record (c) 2021 APA, all rights reserved)

      Impact Statement
      Public Significance Statement-This study contributes to the increasing research in multisensory integration by revealing that an increased amount of sensory information does not necessarily lead to improved performance in rhythmic synchronization. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1037/xhp0000833
JN  - Journal of Experimental Psychology: Human Perception and Performance
VO  - 46
IP  - 10
PG  - 1077-1087
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc19&DO=10.1037%2fxhp0000833

<19. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Music perception testing reveals advantages and continued challenges for children using bilateral cochlear implants. [References].
DP  - Jan 21, 2020
YR  - 2020
LG  - English
AU  - Steel, Morrison M
AU  - Polonenko, Melissa J
AU  - Giannantonio, Sara
AU  - Hopyan, Talar
AU  - Papsin, Blake C
AU  - Gordon, Karen A
SO  - Frontiers in Psychology. Vol.10, 2020, ArtID 3015.
MO  - Jan
IT  - 1664-1078
PT  - Journal
PT  - Peer Reviewed Journal
AB  - A modified version of the child's Montreal Battery of Evaluation of Amusia (cMBEA) was used to assess music perception in children using bilateral cochlear implants. Our overall aim was to promote better performance by children with CIs on the cMBEA by modifying the complement of instruments used in the test and adding pieces transposed in frequency. The 10 test trials played by piano were removed and two high and two low frequency trials added to each of five subtests (20 additional). The modified cMBEA was completed by 14 children using bilateral cochlear implants and 23 peers with normal hearing. Results were compared with performance on the original version of the cMBEA previously reported in groups of similar aged children: 2 groups with normal hearing (n = 23: Hopyan et al., 2012; n = 16: Polonenko et al., 2017), 1 group using bilateral cochlear implants (CIs) (n = 26: Polonenko et al., 2017), 1 group using bimodal (hearing aid and CI) devices (n = 8: Polonenko et al., 2017), and 1 group using unilateral CI (n = 23: Hopyan et al., 2012). Children with normal hearing had high scores on the modified version of the cMBEA and there were no significant score differences from children with normal hearing who completed the original cMBEA. Children with CIs showed no significant improvement in scores on the modified cMBEA compared to peers with CIs who completed the original version of the test. The group with bilateral CIs who completed the modified cMBEA showed a trend toward better abilities to remember music compared to children listening through a unilateral CI but effects were smaller than in previous cohorts of children with bilateral CIs and bimodal devices who completed the original cMBEA. Results confirmed that musical perception changes with the type of instrument and is better for music transposed to higher rather than lower frequencies for children with normal hearing but not for children using bilateral CIs. Overall, the modified version of the cMBEA revealed that modifications to music do not overcome the limitations of the CI to improve music perception for children. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.3389/fpsyg.2019.03015
JN  - Frontiers in Psychology
VO  - 10
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc19&DO=10.3389%2ffpsyg.2019.03015

<20. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Singing proficiency of members of a choir formed by prelingually deafened children with cochlear implants. [References].
DP  - May 2019
YR  - 2019
LG  - English
AU  - Yang, Jing
AU  - Liang, Qi
AU  - Chen, Haotong
AU  - Liu, Yanjun
AU  - Xu, Li
SO  - Journal of Speech, Language, and Hearing Research. Vol.62,(5), 2019, pp. 1561-1573. 
MO  - May
IS  - 1092-4388
IT  - 1558-9102
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Purpose: A group of 10 prelingually deafened children with cochlear implants (CIs) formed a choir and received 21 months of formal music training. The purpose of this study was to evaluate the singing proficiency of these children. Method: The participants included all choir members (7 girls and 3 boys, mean age of 9.5 years old) who were unilateral CI users. Meanwhile, 8 age-matched children with normal hearing were recruited as controls and were trained on 1 song for 2 weeks. Individual singing samples without instrument accompaniment were recorded from all participants. The singing samples were subject to acoustic analysis in which the fundamental frequency (F0) of each note was extracted and the duration was measured. Five metrics were developed and computed to quantify the accuracy of their pitch and rhythm performance. The 5 metrics included (a) percent correct of F0 contour direction of adjacent notes, (b) mean deviation of the normalized F0 across the notes, (c) mean deviation of the pitch intervals, (d) mean deviation of adjacent note duration ratio, and (e) mean absolute deviation of note duration. Results: The choir members with CIs demonstrated high accuracy in both pitch and tempo measures and performed on par with the children with normal hearing. Early start of music training after implantation and use of bimodal hearing contributed to the development of better music ability in these children with CIs. Conclusion: These findings indicated that rigorous music training could facilitate high singing proficiency in prelingually deafened children with CIs. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1044/2019_JSLHR-H-18-0385
JN  - Journal of Speech, Language, and Hearing Research
VO  - 62
IP  - 5
PG  - 1561-1573
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc18&DO=10.1044%2f2019_JSLHR-H-18-0385

<21. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Metrical congruency and kinematic familiarity facilitate temporal binding between musical and dance rhythms. [References].
DP  - Aug 2018
YR  - 2018
LG  - English
AU  - Su, Yi-Huang
SO  - Psychonomic Bulletin & Review. Vol.25,(4), 2018, pp. 1416-1422. 
MO  - Aug
IS  - 1069-9384
IT  - 1531-5320
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Although music and dance are often experienced simultaneously, it is unclear what modulates their perceptual integration. This study investigated how two factors related to music-dance correspondences influenced audiovisual binding of their rhythms: the metrical match between the music and dance, and the kinematic familiarity of the dance movement. Participants watched a point-light figure dancing synchronously to a triple-meter rhythm that they heard in parallel, whereby the dance communicated a triple (congruent) or a duple (incongruent) visual meter. The movement was either the participant's own or that of another participant. Participants attended to both streams while detecting a temporal perturbation in the auditory beat. The results showed lower sensitivity to the auditory deviant when the visual dance was metrically congruent to the auditory rhythm and when the movement was the participant's own. This indicated stronger audiovisual binding and a more coherent bimodal rhythm in these conditions, thus making a slight auditory deviant less noticeable. Moreover, binding in the metrically incongruent condition involving self-generated visual stimuli was correlated with self-recognition of the movement, suggesting that action simulation mediates the perceived coherence between one's own movement and a mismatching auditory rhythm. Overall, the mechanisms of rhythm perception and action simulation could inform the perceived compatibility between music and dance, thus modulating the temporal integration of these audiovisual stimuli. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.3758/s13423-018-1480-3
JN  - Psychonomic Bulletin & Review
VO  - 25
IP  - 4
PG  - 1416-1422
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc17&DO=10.3758%2fs13423-018-1480-3

<22. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Effect of linguistic and musical experience on distributional learning of nonnative lexical tones. [References].
DP  - Oct 2017
YR  - 2017
LG  - English
AU  - Ong, Jia Hoong
AU  - Burnham, Denis
AU  - Escudero, Paola
AU  - Stevens, Catherine J
SO  - Journal of Speech, Language, and Hearing Research. Vol.60,(10), 2017, pp. 2769-2780. 
MO  - Oct
IS  - 1092-4388
IT  - 1558-9102
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Purpose: Evidence suggests that extensive experience with lexical tones or musical training provides an advantage in perceiving nonnative lexical tones. This investigation concerns whether such an advantage is evident in learning nonnative lexical tones based on the distributional structure of the input. Method: Using an established protocol, distributional learning of lexical tones was investigated with tone language (Mandarin) listeners with no musical training (Experiment 1) and nontone language (Australian English) listeners with musical training (Experiment 2). Within each experiment, participants were trained on a bimodal (2-peak) or a unimodal (single peak) distribution along a continuum spanning a Thai lexical tone minimal pair. Discrimination performance on the target minimal pair was assessed before and after training. Results: Mandarin nonmusicians exhibited clear distributional learning (listeners in the bimodal, but not those in the unimodal condition, improved significantly as a function of training), whereas Australian English musicians did not (listeners in both the bimodal and unimodal conditions improved as a function of training). Conclusions: Our findings suggest that veridical perception of lexical tones is not sufficient for distributional learning of nonnative lexical tones to occur. Rather, distributional learning appears to be modulated by domain-specific pitch experience and is constrained possibly by top-down interference. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1044/2016_JSLHR-S-16-0080
JN  - Journal of Speech, Language, and Hearing Research
VO  - 60
IP  - 10
PG  - 2769-2780
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc16&DO=10.1044%2f2016_JSLHR-S-16-0080

<23. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - AMTA undergraduate student research award: Music therapy students' preparedness and training to work with LGBT clients. [References].
DP  - Oct 2017
YR  - 2017
LG  - English
AU  - Wilson, Alexandra
AU  - Geist, Kamile
SO  - Music Therapy Perspectives. Vol.35,(2), 2017, pp. 226-227. 
MO  - Oct
IS  - 0734-6875
IT  - 2053-7387
PT  - Journal
PT  - Peer Reviewed Journal
AB  - The purpose of this study was to describe self-report data of current preparedness and training to work with LGBT clients from music therapy students at a public university in the United States. A questionnaire was developed that included six demographic questions; two questions related to training sources; twelve questions related to knowledge about clinical practice with LGBT people; and five items designed to measure perceived preparedness. Items related to clinical knowledge were informed by best-practices guidelines. Most participants were undergraduate students, including freshmen (25.6%), sophomores (14%), juniors (27.9%), Bimodal distribution of preparedness suggests that there may be two different groups of music therapy students: one group of students who perceive themselves as somewhat prepared and another group who perceive themselves as somewhat unprepared. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1093/mtp/mix002
JN  - Music Therapy Perspectives
VO  - 35
IP  - 2
PG  - 226-227
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc16&DO=10.1093%2fmtp%2fmix002

<24. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Facial biases on vocal perception and memory. [References].
DP  - Jun 2017
YR  - 2017
LG  - English
AU  - Boltz, Marilyn G
SO  - Acta Psychologica. Vol.177, 2017, pp. 54-68. 
MO  - Jun
IS  - 0001-6918
IT  - 1873-6297
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Does a speaker's face influence the way their voice is heard and later remembered? This question was addressed through two experiments where in each, participants listened to middle-aged voices accompanied by faces that were either age-appropriate, younger or older than the voice or, as a control, no face at all. In Experiment 1, participants evaluated each voice on various acoustical dimensions and speaker characteristics. The results showed that facial displays influenced perception such that the same voice was heard differently depending on the age of the accompanying face. Experiment 2 further revealed that facial displays led to memory distortions that were age-congruent in nature. These findings illustrate that faces can activate certain social categories and preconceived stereotypes that then influence vocal and person perception in a corresponding fashion. Processes of face/voice integration are very similar to those of music/film, indicating that the two areas can mutually inform one another and perhaps, more generally, reflect a centralized mechanism of cross-sensory integration. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1016/j.actpsy.2017.04.013
JN  - Acta Psychologica
VO  - 177
PG  - 54-68
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc16&DO=10.1016%2fj.actpsy.2017.04.013

<25. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Weighted integration suggests that visual and tactile signals provide independent estimates about duration. [References].
DP  - May 2017
YR  - 2017
LG  - English
AU  - Ball, Danny M
AU  - Arnold, Derek H
AU  - Yarrow, Kielan
SO  - Journal of Experimental Psychology: Human Perception and Performance. Vol.43,(5), 2017, pp. 868-880. 
MO  - May
IS  - 0096-1523
IT  - 1939-1277
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Humans might possess either a single (amodal) internal clock or multiple clocks for different sensory modalities. Sensitivity could be improved by the provision of multiple signals. Such improvements can be predicted quantitatively, assuming estimates are combined by summation, a process described as optimal when summation is weighted in accordance with the variance associated with each of the initially independent estimates. This possibility was assessed for visual and tactile information regarding temporal intervals. In Experiment 1, 12 musicians and 12 nonmusicians judged durations of 300 and 600 ms, compared to test values spanning these standards. Bimodal precision increased relative to unimodal conditions, but not to the extent predicted by optimally weighted summation. In Experiment 2, 6 musicians and 6 other participants each judged 6 standards, ranging from 100 ms to 600 ms, with conflicting cues providing a measure of the weight assigned to each sensory modality. A weighted integration model best fitted these data, with musicians more likely to select near-optimal weights than nonmusicians. Overall, data were consistent with the existence of separate visual and tactile clock components at either the counter/integrator or memory stages. Independent estimates are passed to a decisional process, but not always combined in a statistically optimal fashion. (PsycInfo Database Record (c) 2021 APA, all rights reserved)

      Impact Statement
      Public Significance Statement-We are able to judge the duration of events as they unfold (e.g., the time for which somebody holds our gaze). Sometimes, this information is conveyed to several of our senses at once (e.g., both seeing and feeling the duration of a caress). Theorists argue about whether time intervals are calculated separately for each sense or rely on a common centralized timer. This study suggests that when people experience the duration of events via both vision and touch, they gain a multisensory benefit, performing better than when they receive just visual or just tactile stimulation. This kind of benefit can only accrue if time is first estimated independently within each sense, suggesting that separate timers exist. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1037/xhp0000368
JN  - Journal of Experimental Psychology: Human Perception and Performance
VO  - 43
IP  - 5
PG  - 868-880
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc16&DO=10.1037%2fxhp0000368

<26. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Learning novel musical pitch via distributional learning. [References].
DP  - Jan 2017
YR  - 2017
LG  - English
AU  - Ong, Jia Hoong
AU  - Burnham, Denis
AU  - Stevens, Catherine J
SO  - Journal of Experimental Psychology: Learning, Memory, and Cognition. Vol.43,(1), 2017, pp. 150-157. 
MO  - Jan
IS  - 0278-7393
IT  - 1939-1285
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Because different musical scales use different sets of intervals and, hence, different musical pitches, how do music listeners learn those that are in their native musical system? One possibility is that musical pitches are acquired in the same way as phonemes, that is, via distributional learning, in which learners infer knowledge from the distributional structure of their input. In this study, we investigate whether novel musical pitch can be acquired distributionally. Nonmusician adults were trained on a continuum spanning a novel musical chord minimal pair (i.e., a novel chord and a mistuned version of that chord) in which the continuum was presented either in a bimodal distribution, with a modal peak at each end of the continuum, or in a unimodal distribution, with a single central modal peak. Discrimination of target minimal pairs was assessed before and after exposure to the distribution. Distributional learning would be said to occur if learners in the bimodal condition, but not those in the unimodal condition, showed evidence of learning, as indexed by improvement in discriminating the minimal pair from pretest to posttest. This indeed was the outcome, suggesting that the building blocks of musical melody-musical pitch-can be acquired using distributional learning. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1037/xlm0000286
JN  - Journal of Experimental Psychology: Learning, Memory, and Cognition
VO  - 43
IP  - 1
PG  - 150-157
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc16&DO=10.1037%2fxlm0000286

<27. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Factors affecting daily cochlear implant use in children: Datalogging evidence. [References].
DP  - Nov-Dec 2016
YR  - 2016
LG  - English
AU  - Easwar, Vijayalakshmi
AU  - Sanfilippo, Joseph
AU  - Papsin, Blake
AU  - Gordon, Karen
SO  - Journal of the American Academy of Audiology. Vol.27,(10), 2016, pp. 824-838. 
MO  - Nov-Dec
IS  - 1050-0545
IT  - 2157-3107
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Background: Children with profound hearing loss can gain access to sound through cochlear implants (CIs), but these devices must be worn consistently to promote auditory development. Although subjective parent reports have identified several factors limiting long-term CI use in children, it is also important to understand the day-to-day issues which may preclude consistent device use. In the present study, objective measures gathered through datalogging software were used to quantify the following in children: (1) number of hours of CI use per day, (2) practical concerns including repeated disconnections between the external transmission coil and the internal device (termed "coil-offs"), and (3) listening environments experienced during daily use. Purpose: This study aimed to (1) objectively measure daily CI use and factors influencing consistent device use in children using one or two CIs and (2) evaluate the intensity levels and types of listening environments children are exposed to during daily CI use. Research Design: Retrospective analysis. Study Sample: Measures of daily CI use were obtained from 146 pediatric users of Cochlear Nucleus 6 speech processors. The sample included 5 unilateral, 40 bimodal, and 101 bilateral CI users (77 simultaneously and 24 sequentially implanted). Data Collection and Analysis: Daily CI use, duration, and frequency of coil-offs per day, and the time spent in multiple intensity ranges and environment types were extracted from the datalog saved during clinic appointments. Multiple regression analyses were completed to predict daily CI use based on child-related demographic variables, and to evaluate the effects of age on coil-offs and environment acoustics. Results: Children used their CIs for 9.86 +/- 3.43 hr on average on a daily basis, with use exceeding 9 hr per day in ~64% of the children. Daily CI use reduced significantly with increasing durations of coil-off (p = 0.027) and increased significantly with longer CI experience (p < 0.001) and pre-CI acoustic experience (p < 0.001), when controlled for the child's age. Total time in sound (sum of CI and pre-CI experience) was positively correlated with CI use (r = 0.72, p < 0.001). Longer durations of coil-off were associated with higher frequency of coil-offs (p < 0.001). The frequency of coil-offs ranged from 0.99 to 594.10 times per day and decreased significantly with age (p < 0.001). Daily CI use and frequency of coil-offs did not vary significantly across known etiologies. Listening environments of all children typically ranged between 50 and 70 dBA. Children of all ages were exposed to speech in noisy environments. Environment classified as "music" was identified more often in younger children. Conclusions: The majority of children use their CIs consistently, even during the first year of implantation. The frequency of coil-offs is a practical challenge in infants and young children, and demonstrates the need for improved coil retention methods for pediatric use. Longer hearing experience and shorter coil-off time facilitates consistent CI use. Children are listening to speech in noisy environments most often, thereby indicating a need for better access to binaural cues, signal processing, and stimulation strategies to aid listening. Study findings could be useful in parent counseling of young and/or new CI users. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.3766/jaaa.15138
JN  - Journal of the American Academy of Audiology
VO  - 27
IP  - 10
PG  - 824-838
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc15&DO=10.3766%2fjaaa.15138

<28. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Naive learners show cross-domain transfer after distributional learning: The case of lexical and musical pitch. [References].
DP  - Aug 8, 2016
YR  - 2016
LG  - English
AU  - Ong, Jia Hoong
AU  - Burnham, Denis
AU  - Stevens, Catherine J
AU  - Escudero, Paola
SO  - Frontiers in Psychology. Vol.7, 2016, ArtID 1189.
MO  - Aug
IT  - 1664-1078
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Experienced listeners of a particular acoustic cue in either speech or music appear to have an advantage when perceiving a similar cue in the other domain (i.e., they exhibit cross-domain transfer). One explanation for cross-domain transfer relates to the acquisition of the foundations of speech and music: if acquiring pitch-based elements in speech or music results in heightened attention to pitch in general, then cross-domain transfer of pitch may be observed, which may explain the cross-domain phenomenon seen among listeners of a tone language and listeners with musical training. Here, we investigate this possibility in naive adult learners, who were trained to acquire pitch-based elements using a distributional learning paradigm, to provide a proof-of-concept for the explanation. Learners were exposed to a stimulus distribution spanning either a Thai lexical tone minimal pair or a novel musical chord minimal pair. Within each domain, the distribution highlights pitch to facilitate learning of two different sounds (Bimodal distribution) or the distribution minimizes pitch so that the input is inferred to be from a single sound (Unimodal distribution). Learning was assessed before and after exposure to the distribution using discrimination tasks with both Thai tone and musical chord minimal pairs. We hypothesize: (i) distributional learning for learners in both the tone and the chord distributions, that is, pre-to-post improvement in discrimination after exposure to the Bimodal but not the Unimodal distribution; and (ii) for both the tone and chord conditions, learners in the Bimodal conditions but not those in the Unimodal conditions will show cross-domain transfer, as indexed by improvement in discrimination of test items in the domain other than what they were trained on. The results support both hypotheses, suggesting that distributional learning is not only used to acquire the foundations of speech and music, but may also play a role in cross-domain transfer: as a result of learning primitives based on a particular cue, learners show heightened attention to that cue in any auditory signal. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.3389/fpsyg.2016.01189
JN  - Frontiers in Psychology
VO  - 7
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc15&DO=10.3389%2ffpsyg.2016.01189

<29. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Musical instrument identification in simulated electric acoustic hearing and in cochlear implant users with contralateral hearing aids. [References].
DP  - Sep 2016
YR  - 2016
LG  - English
AU  - Hossain, Shaikat
AU  - Montazeri, Vahid
AU  - Assmann, Peter F
SO  - Psychomusicology: Music, Mind, and Brain. Vol.26,(3), 2016, pp. 270-278. 
MO  - Sep
IS  - 0275-3987
IT  - 2162-1535
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Two experiments were conducted on musical instrument identification. The first experiment investigated performance of normal-hearing (NH) listeners in a closed-set musical instrument identification involving vocoder simulations of a cochlear implant (CI) and electric acoustic stimulation (EAS; where a hearing aid supplements the CI to access low-frequency residual hearing). The second experiment investigated performance on the same task by bimodal CI users who normally wore a hearing aid on their contralateral ear. While the NH listeners exhibited an EAS benefit over the CI condition for particular instruments, bimodal CI users did not show a consistent benefit of EAS over CI alone and exhibited the highest performance when listening through their hearing aid alone. This finding suggests that there may be factors (such as duration of device use and interaural frequency mismatch) that may currently limit the EAS benefit for music listening in the bimodal CI population. The identification rates varied across the different musical instruments, with higher scores for instruments with more rhythmic excerpts. This finding supports previous reports of the relatively greater salience of temporal envelope and rhythmic cues over other timbral and pitch-based cues in CIs. The comparison of the results of the two experiments emphasizes that predictions based on simulations may not always translate to clinical outcomes in the CI population. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1037/pmu0000157
JN  - Psychomusicology: Music, Mind, and Brain
VO  - 26
IP  - 3
PG  - 270-278
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc15&DO=10.1037%2fpmu0000157

<30. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Utility of bilateral acoustic hearing in combination with electrical stimulation provided by the cochlear implant. [References].
DP  - Jun 2016
YR  - 2016
LG  - English
AU  - Plant, Kerrie
AU  - Babic, Leanne
SO  - International Journal of Audiology. Vol.55,(Suppl 2), 2016, pp. S31-S38. 
MO  - Jun
IS  - 1499-2027
IT  - 1708-8186
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Objective: The aim of the study was to quantify the benefit provided by having access to amplified acoustic hearing in the implanted ear for use in combination with contralateral acoustic hearing and the electrical stimulation provided by the cochlear implant. Design: Measures of spatial and non-spatial hearing abilities were obtained to compare performance obtained with different configurations of acoustic hearing in combination with electrical stimulation. In the combined listening condition participants had access to bilateral acoustic hearing whereas the bimodal condition used acoustic hearing contralateral to the implanted ear only. Experience was provided with each of the listening conditions using a repeated-measures A-B-B-A experimental design. Study sample: Sixteen post-linguistically hearing-impaired adults participated in the study. Results: Group mean benefit was obtained with use of the combined mode on measures of speech recognition in coincident speech in noise, localization ability, subjective ratings of real-world benefit, and musical sound quality ratings. Conclusions: Access to bilateral acoustic hearing after cochlear implantation provides significant benefit on a range of functional measures. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.3109/14992027.2016.1150609
JN  - International Journal of Audiology
VO  - 55
IP  - Suppl 2
PG  - S31-S38
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc15&DO=10.3109%2f14992027.2016.1150609

<31. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - The effects of hearing aid programming on speech, prosody and music perception in bimodal listeners.DP  - 2016
YR  - 2016
LG  - English
AU  - Siburt, Hannah W
SO  - Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.76,(12-B(E)), 2016, pp. No Pagination Specified. 
IS  - 0419-4217
IB  - 978-1321962628
PT  - Dissertation Abstract
AB  - The purpose of this double blind study was to investigate the effects of hearing aid programming in bimodal listeners on speech in noise, prosody (emotion) and music perception. Participants were experienced unilateral cochlear implant (CI) recipients. All participants were fit with the same power BTE hearing aid (Starkey XSeries Power Plus 110). The hearing aid was programmed using a standard NAL-NL2 fitting method as well as a Low Frequency Program (LFP) and participants were given 3-4 weeks to wear each in their daily lives. The programming was counterbalanced. Objective outcome testing included CNC, BKB-SIN, AzBio, ANL, UW-CAMP, and the Florida Affect Battery. Subjective feedback was obtained via the SSQ during each study session. Effort and difficulty ratings were obtained after each objective test. Results of this study further support the current bimodal literature indicating benefit from the addition of a hearing aid in the ear contralateral to the cochlear implant regardless of the hearing aid programming strategy. Bimodal benefit was observed objective measures of speech in noise, music and prosody. Additionally, the amount of effort and level of difficulty decreased significantly in the bimodal condition for all subjects on the prosody measures. Furthermore, study results suggest a significant bimodal benefit for individuals with only minimal measureable hearing thresholds. The results of this study will potentially assist clinicians with recommendations for maximizing auditory perception in the non-implanted ear of unilateral cochlear implant users. Results may also provide clinical recommendations for programming a hearing aid in the ear contralateral to the cochlear implant to improve prosody perception and speech understanding in noise. The outcome of this study provides a basis for future research in bimodal hearing aid programming and clinical recommendation of hearing devices in individuals with severe to profound hearing loss. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
JN  - Dissertation Abstracts International: Section B: The Sciences and Engineering
VO  - 76
IP  - 12-B(E)
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc15&AN=2016-21251-126

<32. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Differences in perception of musical stimuli among acoustic, electric, and combined modality listeners. [References].
DP  - May 2015
YR  - 2015
LG  - English
AU  - Prentiss, Sandra M
AU  - Friedland, David R
AU  - Nash, John J
AU  - Runge, Christina L
SO  - Journal of the American Academy of Audiology. Vol.26,(5), 2015, pp. 494-501. 
MO  - May
IS  - 1050-0545
IT  - 2157-3107
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Background: Cochlear implants have shown vast improvements in speech understanding for those with severe to profound hearing loss; however, music perception remains a challenge for electric hearing. It is unclear whether the difficulties arise from limitations of sound processing, the nature of a damaged auditory system, or a combination of both. Purpose: To examine music perception performance with different acoustic and electric hearing configurations. Research Design: Chord discrimination and timbre perception were tested in subjects representing four daily-use listening configurations: unilateral cochlear implant (CI), contralateral bimodal (CIHA), bilateral hearing aid (MAMA) and normal-hearing (NH) listeners. A same-different task was used for discrimination of two chords played on piano. Timbre perception was assessed using a 10-instrument forced-choice identification task. Study Sample: Fourteen adults were included in each group, none of whom were professional musicians. Data Collection and Analysis: The number of correct responses was divided by the total number of presentations to calculate scores in percent correct. Data analyses were performed with Kruskal-Wallis one-way analysis of variance and linear regression. Results: Chord discrimination showed a narrow range of performance across groups, with mean scores ranging between 72.5% (CI) and 88.9% (NH). Significant differences were seen between the NH and all hearing-impaired groups. Both the HAHA and CIHA groups performed significantly better than the CI groups, and no significant differences were observed between the HAHA and CIHA groups. Timbre perception was significantly poorer for the hearing-impaired groups (mean scores ranged from 50.3-73.9%) compared to NH (95.2%). Significantly better performance was observed in the HAHA group as compared to both groups with electric hearing (CI and CIHA). There was no significant difference in performance between the CIHA and CI groups. Timbre perception was a significantly more difficult task than chord discrimination for both the CI and CIHA groups, yet the easier task for the NH group. A significant difference between the two tasks was not seen in the HAHA group. Conclusion: Having impaired hearing decreases performance compared to NH across both chord discrimination and timbre perception tasks. For chord discrimination, having acoustic hearing improved performance compared to electric hearing only. Timbre perception distinguished those with acoustic hearing from those with electric hearing. Those with bilateral acoustic hearing, even if damaged, performed significantly better on this task than those requiring electrical stimulation, which may indicate that CI sound processing fails to capture and deliver the necessary acoustic cues for timbre perception. Further analysis of timbre characteristics in electric hearing may contribute to advancements in programming strategies to obtain optimal hearing outcomes. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
DO  - https://dx.doi.org/10.3766/jaaa.14098
JN  - Journal of the American Academy of Audiology
VO  - 26
IP  - 5
PG  - 494-501
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc14&DO=10.3766%2fjaaa.14098

<33. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Visual and aural modes of perception in choral performance evaluations.DP  - 2015
YR  - 2015
LG  - English
AU  - Selvey, Jeremiah David
SO  - Dissertation Abstracts International Section A: Humanities and Social Sciences. Vol.76,(6-A(E)), 2015, pp. No Pagination Specified. 
IS  - 0419-4209
IB  - 978-1-321-52172-6
PT  - Dissertation Abstract
AB  - A live musical performance is influenced by both the visual and aural information associated with that performance. A growing body of literature has demonstrated that the experience of a live musical performance is largely dominated by the visual information accompanying and/or associated with that performance, despite the common assumption that music is mostly or completely a sonic experience. This study extended in several ways prior cross-modal research that examined the effects of visual and aural information on aural performances by wind ensembles (Morrison, Price, Smedley, & Meals, 2014) and visual performances by conductors (Bender & Hancock, 2010). First, the study used collegiate choral performances, rather than wind ensembles. Second, the study broadened the target population. Prior research involved secondary and college students who were in ensembles or music classes, while the current study involved adults from the larger population who had ensemble experience. This broadening of the participant pool also resulted in a much greater range of experience (from 2 to 25+ years) in a conducted music ensemble than prior research and included not only singers and instrumentalists (as in prior research), but also conductors. Finally, this study was the first in this line of research to use an online platform instead of a classroom environment. There were four primary quantitative purposes for this study. First, the researcher proposed a fully crossed experimental exploration of the effects of conducting expressivity conditions (low vs. high) and choir expressivity conditions (minimal vs. maximal) on the perception of both choral and conductor expressivity, using identical musical passages and identical conducting conditions for comparison. Additionally, the researcher sought to understand how choir and conductor ratings would compare across presentation modes (single vs. dual) of visual and aural stimuli. Third, the researcher tested for correlations of conductor and choir scores in each of the paired expressivity treatment conditions. Finally, the researcher wanted to understand the predictive contributions of various collected factors on the conductor and choir expressivity assessment scores. The purpose of soliciting qualitative comments was a phenomenological inquiry into the construct of conductor and ensemble expressivity. This inquiry produced emergent ideas regarding the construct of expressivity in an ensemble performance and illuminated how people might differ in their evaluation processes of conductor and choir expressivity. Adult participants with prior or current experience in a conducted music ensemble, rated conductor and/or choir expressivity on an anchored scale from 1 (low) to 10 (high) and, if they desired, commented on each of their ratings. Additionally, participants were asked to share any additional ideas or thoughts regarding choral expressivity. The results of the quantitative data indicated a dominance of the visual mode in a bi-modal exploration of musical performance. Results revealed that both conductor and choir ratings were significantly impacted by the four paired expressivity conditions that resulted from the fully crossed design. The study also demonstrated that low-expressivity conducting is deleterious to the perception of both minimally and maximally expressive performances, while the perception of low-expressivity conducting is not influenced by a university choir's expressivity in performance. Two multiple linear regressions revealed that neither experience (2-25+ years) nor role (conductor, singer, instrumentalist) predicted choir or conductor ratings; furthermore, in the case of both conductor and choir ratings, conductor expressivity was a stronger predictor of the scores. Among the qualitative findings regarding choral expressivity emerged two lenses-cognitive and affective-through which participant observers se... (PsycInfo Database Record (c) 2021 APA, all rights reserved)
JN  - Dissertation Abstracts International Section A: Humanities and Social Sciences
VO  - 76
IP  - 6-A(E)
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc14&AN=2015-99230-358

<34. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Experience changes how emotion in music is judged: Evidence from children listening with bilateral cochlear implants, bimodal devices, and normal hearing. [References].
DP  - Aug 28, 2015
YR  - 2015
LG  - English
AU  - Giannantonio, Sara
AU  - Polonenko, Melissa J
AU  - Papsin, Blake C
AU  - Paludetti, Gaetano
AU  - Gordon, Karen A
SO  - PLoS ONE. Vol.10,(8), 2015, ArtID e0136685.
MO  - Aug
IT  - 1932-6203
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Children using unilateral cochlear implants abnormally rely on tempo rather than mode cues to distinguish whether a musical piece is happy or sad. This led us to question how this judgment is affected by the type of experience in early auditory development. We hypothesized that judgments of the emotional content of music would vary by the type and duration of access to sound in early life due to deafness, altered perception of musical cues through new ways of using auditory prostheses bilaterally, and formal music training during childhood. Seventy-five participants completed the Montreal Emotion Identification Test. Thirty-three had normal hearing (aged 6.6 to 40.0 years) and 42 children had hearing loss and used bilateral auditory prostheses (31 bilaterally implanted and 11 unilaterally implanted with contralateral hearing aid use). Reaction time and accuracy were measured. Accurate judgment of emotion in music was achieved across ages and musical experience. Musical training accentuated the reliance on mode cues which developed with age in the normal hearing group. Degrading pitch cues through cochlear implant-mediated hearing induced greater reliance on tempo cues, but mode cues grew in salience when at least partial acoustic information was available through some residual hearing in the contralateral ear. Finally, when pitch cues were experimentally distorted to represent cochlear implant hearing, individuals with normal hearing (including those with musical training) switched to an abnormal dependence on tempo cues. The data indicate that, in a western culture, access to acoustic hearing in early life promotes a preference for mode rather than tempo cues which is enhanced by musical training. The challenge to these preferred strategies during cochlear implant hearing (simulated and real), regardless of musical training, suggests that access to pitch cues for children with hearing loss must be improved by preservation of residual hearing and improvements in cochlear implant technology. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1371/journal.pone.0136685
JN  - PLoS ONE
VO  - 10
IP  - 8
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc14&DO=10.1371%2fjournal.pone.0136685

<35. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Contributions of electric and acoustic hearing to bimodal speech and music perception. [References].
DP  - Mar 19, 2015
YR  - 2015
LG  - English
AU  - Crew, Joseph D
AU  - Galvin, John J III
AU  - Landsberger, David M
AU  - Fu, Qian-Jie
SO  - PLoS ONE. Vol.10,(3), 2015, ArtID e0120279.
MO  - Mar
IT  - 1932-6203
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Cochlear implant (CI) users have difficulty understanding speech in noisy listening conditions and perceiving music. Aided residual acoustic hearing in the contralateral ear can mitigate these limitations. The present study examined contributions of electric and acoustic hearing to speech understanding in noise and melodic pitch perception. Data was collected with the CI only, the hearing aid (HA) only, and both devices together (CI + HA). Speech reception thresholds (SRTs) were adaptively measured for simple sentences in speech babble. Melodic contour identification (MCI) was measured with and without a masker instrument; the fundamental frequency of the masker was varied to be overlapping or non-overlapping with the target contour. Results showed that the CI contributes primarily to bimodal speech perception and that the HA contributes primarily to bimodal melodic pitch perception. In general, CI + HA performance was slightly improved relative to the better ear alone (CI-only) for SRTs but not for MCI, with some subjects experiencing a decrease in bimodal MCI performance relative to the better ear alone (HA-only). Individual performance was highly variable, and the contribution of either device to bimodal perception was both subject- and task-dependent. The results suggest that individualized mapping of CIs and HAs may further improve bimodal speech and music perception. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1371/journal.pone.0120279
JN  - PLoS ONE
VO  - 10
IP  - 3
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc14&DO=10.1371%2fjournal.pone.0120279

<36. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Song recognition by young children with cochlear implants: Comparison between unilateral, bilateral, and bimodal users. [References].
DP  - Oct 2014
YR  - 2014
LG  - English
AU  - Bartov, Tamar
AU  - Most, Tova
SO  - Journal of Speech, Language, and Hearing Research. Vol.57,(5), 2014, pp. 1929-1941. 
MO  - Oct
IS  - 1092-4388
IT  - 1558-9102
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Purpose: To examine song identification by preschoolers with normal hearing (NH) versus preschoolers with cochlear implants (CIs). Method: Participants included 45 children ages 3;8-7;3 (years;months): 12 with NH and 33 with CIs, including 10 with unilateral CI, 14 with bilateral CIs, and 9 bimodal users (CI-HA) with unilateral CI and contralateral hearing aid. Preschoolers were asked to identify children's songs presented via 5 versions: (a) full (lyrics sung with piano accompaniment); (b) a cappella (only lyrics); (c) melodic (matching main melodic contour); (d) tonal (only pitch information); and (e) rhythmic (only song's rhythm). Results: The NH group surpassed all CI groups at identifying songs via melodic and tonal versions, but no significant differences emerged between the NH group and any CI group via full, a cappella, or rhythmic versions. Among the CI groups, no significant differences emerged via melodic or rhythmic versions, but bimodal users performed significantly better than bilateral users via the tonal version. Chronological age and duration of CI use correlated significantly with identification via the rhythmic version. Conclusion: Bimodal users showed an advantage in identifying songs in the tonal version through use of complementary information. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1044/2014_JSLHR-H-13-0190
JN  - Journal of Speech, Language, and Hearing Research
VO  - 57
IP  - 5
PG  - 1929-1941
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc13&DO=10.1044%2f2014_JSLHR-H-13-0190

<37. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Audiovisual beat induction in complex auditory rhythms: Point-light figure movement as an effective visual beat. [References].
DP  - Sep 2014
YR  - 2014
LG  - English
AU  - Su, Yi-Huang
SO  - Acta Psychologica. Vol.151, 2014, pp. 40-50. 
MO  - Sep
IS  - 0001-6918
IT  - 1873-6297
PT  - Journal
PT  - Peer Reviewed Journal
AB  - This study investigated whether explicit beat induction in the auditory, visual, and audiovisual (bimodal) modalities aided the perception of weakly metrical auditory rhythms, and whether it reinforced attentional entrainment to the beat of these rhythms. The visual beat-inducer was a periodically bouncing point-light figure, which aimed to examine whether an observed rhythmic human movement could induce a beat that would influence auditory rhythm perception. In two tasks, participants listened to three repetitions of an auditory rhythm that were preceded and accompanied by (1) an auditory beat, (2) a bouncing point-light figure, (3) a combination of (1) and (2) synchronously, or (4) a combination of (1) and (2), with the figure moving in anti-phase to the auditory beat. Participants reproduced the auditory rhythm subsequently (Experiment 1), or detected a possible temporal change in the third repetition (Experiment 2). While an explicit beat did not improve rhythm reproduction, possibly due to the syncopated rhythms when a beat was imposed, bimodal beat induction yielded greater sensitivity to a temporal deviant in on-beat than in off-beat positions. Moreover, the beat phase of the figure movement determined where on-beat accents were perceived during bimodal induction. Results are discussed with regard to constrained beat induction in complex auditory rhythms, visual modulation of auditory beat perception, and possible mechanisms underlying the preferred visual beat consisting of rhythmic human motions. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1016/j.actpsy.2014.05.016
JN  - Acta Psychologica
VO  - 151
PG  - 40-50
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc13&DO=10.1016%2fj.actpsy.2014.05.016

<38. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Crossmodal interactions in the perception of expressivity in musical performance. [References].
DP  - Feb 2014
YR  - 2014
LG  - English
AU  - Vuoskoski, Jonna K
AU  - Thompson, Marc R
AU  - Clarke, Eric F
AU  - Spence, Charles
SO  - Attention, Perception, & Psychophysics. Vol.76,(2), 2014, pp. 591-604. 
MO  - Feb
IS  - 1943-3921
IT  - 1943-393X
PT  - Journal
PT  - Peer Reviewed Journal
AB  - In musical performance, bodily gestures play an important role in communicating expressive intentions to audiences. Although previous studies have demonstrated that visual information can have an effect on the perceived expressivity of musical performances, the investigation of audiovisual interactions has been held back by the technical difficulties associated with the generation of controlled, mismatching stimuli. With the present study, we aimed to address this issue by utilizing a novel method in order to generate controlled, balanced stimuli that comprised both matching and mismatching bimodal combinations of different expressive intentions. The aim of Experiment 1 was to investigate the relative contributions of auditory and visual kinematic cues in the perceived expressivity of piano performances, and in Experiment 2 we explored possible crossmodal interactions in the perception of auditory and visual expressivity. The results revealed that although both auditory and visual kinematic cues contribute significantly to the perception of overall expressivity, the effect of visual kinematic cues appears to be somewhat stronger. These results also provide preliminary evidence of crossmodal interactions in the perception of auditory and visual expressivity. In certain performance conditions, visual cues had an effect on the ratings of auditory expressivity, and auditory cues had a small effect on the ratings of visual expressivity. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.3758/s13414-013-0582-2
JN  - Attention, Perception, & Psychophysics
VO  - 76
IP  - 2
PG  - 591-604
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc13&DO=10.3758%2fs13414-013-0582-2

<39. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Playing in the shadows: Fictions of race and Blackness in postwar Japanese literature.DP  - 2013
YR  - 2013
LG  - English
AU  - Bridges, William H. IV
SO  - Dissertation Abstracts International Section A: Humanities and Social Sciences. Vol.74,(4-A(E)), 2013, pp. No Pagination Specified. 
IS  - 0419-4209
IB  - 978-1-267-78357-8
PT  - Dissertation Abstract
AB  - This dissertation is the first book-length study to consider the literature, primarily prose narratives, engendered by postwar Japanese authors' encounters with African Americans and African American literature. The dissertation argues that the "blackness" of postwar Japanese fiction is written in two modalities. The first mode fixates on the representation, and thus the imaginary mastery, of black (typically male) bodies. Given the influx of African American soldiers and black culture in Japan evoked by the Allied Occupation, the early postwar period saw an uptick in works written in the first mode, i.e. the postwar novellas of authors such as Ishikawa Jun and Kojima Nobuo. The very influx of black people and culture that catalyzed production in the first mode, however, also served as an impetus for the creation of organizations such as the Kokujin kenkyu no kai (The Japanese Association for Negro Studies) and literary endeavors such as the Kokujin bungaku zenshu (The Complete Anthology of Black Literature). This milieu sparked Japanese authors'-Nakagami Kenji and e Kenzabur are two such examples-interest in reading, interpreting, critiquing and, ultimately, incorporating the tropes and techniques of African American literature and jazz performance into their own literary works. Such incorporation leads to a second mode of writing blackness in Japanese literature. The blackness of literary works written in the second mode arises not by virtue of the representation of black characters, but by virtue of the works' investment in the possibility of writing Japanese literature that has black literature and history in its intertextual and contextual networks. Whereas previous scholarship itself has fixated on the first mode, this dissertation amalgamates textual analysis and literary historical investigation in order to fully delineate the rich history of black-Japanese literary exchange and bimodal writing of blackness in Japanese literature Through five case studies that progress chronologically from Ishikawa Jun's "gon densetsu" (The Legend of Gold, 1946) to Yamada Eimi's Payday!!! (2003), this dissertation both reconsiders postwar Japanese literary representations of blackness and argues that black-Japanese literary exchange created a vein of modern Japanese literature shaped by Japanese authors' interpretations of blackness and black fiction. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
JN  - Dissertation Abstracts International Section A: Humanities and Social Sciences
VO  - 74
IP  - 4-A(E)
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc12&AN=2013-99190-422

<40. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Synchronization with competing visual and auditory rhythms: Bouncing ball meets metronome. [References].
DP  - Jul 2013
YR  - 2013
LG  - English
AU  - Hove, Michael J
AU  - Iversen, John R
AU  - Zhang, Allen
AU  - Repp, Bruno H
SO  - Psychological Research. Vol.77,(4), 2013, pp. 388-398. 
MO  - Jul
IS  - 0340-0727
IT  - 1430-2772
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Synchronization of finger taps with periodically flashing visual stimuli is known to be much more variable than synchronization with an auditory metronome. When one of these rhythms is the synchronization target and the other serves as a distracter at various temporal offsets, strong auditory dominance is observed. However, it has recently been shown that visuomotor synchronization improves substantially with moving stimuli such as a continuously bouncing ball. The present study pitted a bouncing ball against an auditory metronome in a target-distracter synchronization paradigm, with the participants being auditory experts (musicians) and visual experts (video gamers and ball players). Synchronization was still less variable with auditory than with visual target stimuli in both groups. For musicians, auditory stimuli tended to be more distracting than visual stimuli, whereas the opposite was the case for the visual experts. Overall, there was no main effect of distracter modality. Thus, a distracting spatiotemporal visual rhythm can be as effective as a distracting auditory rhythm in its capacity to perturb synchronous movement, but its effectiveness also depends on modality-specific expertise. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1007/s00426-012-0441-0
JN  - Psychological Research
VO  - 77
IP  - 4
PG  - 388-398
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc12&DO=10.1007%2fs00426-012-0441-0

<41. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Exploring the impact of congenital visual impairment on the development of absolute pitch using a new online assessment tool: A preliminary study. [References].
DP  - Dec 2012
YR  - 2012
LG  - English
AU  - Dimatati, Maria
AU  - Heaton, Pamela
AU  - Pring, Linda
AU  - Downing, John
AU  - Ockelford, Adam
SO  - Psychomusicology: Music, Mind, and Brain. Vol.22,(2), 2012, pp. 129-133. 
MO  - Dec
IS  - 0275-3987
IT  - 2162-1535
IB  - 1-4338-1356-4
PT  - Journal
PT  - Peer Reviewed Journal
AB  - A high incidence of absolute pitch has been reported among individuals with visual impairment (VI), while recent behavioral and imaging evidence has indicated that enhanced abilities in the auditory domain result from the cross-modal takeover of the visually deafferented occipital areas. In this study, we tested the identification of musical pitch associated with verbal labels in children with congenital VI, together with a group of fully sighted children who acted as a comparison group, using a novel online assessment tool. The results indicated superior naming of musical pitch in the group with VI compared with the control group. Moreover, a bimodal distribution was found in the VI group in terms of the number of accurate pitch identifications. These preliminary findings suggest that enhanced pitch-naming ability in individuals with severe VI may be due to early differences in neural development brought about by loss of sight. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1037/a0030857
JN  - Psychomusicology: Music, Mind, and Brain
VO  - 22
IP  - 2
PG  - 129-133
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc11&DO=10.1037%2fa0030857

<42. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Contribution of temporal processing skills to reading comprehension in 8-year-olds: Evidence for a mediation effect of phonological awareness. [References].
DP  - Jul-Aug 2012
YR  - 2012
LG  - English
AU  - Malenfant, Nathalie
AU  - Grondin, Simon
AU  - Boivin, Michel
AU  - Forget-Dubois, Nadine
AU  - Robaey, Philippe
AU  - Dionne, Ginette
SO  - Child Development. Vol.83,(4), 2012, pp. 1332-1346. 
MO  - Jul-Aug
IS  - 0009-3920
IT  - 1467-8624
PT  - Journal
PT  - Peer Reviewed Journal
AB  - This study tested whether the association between temporal processing (TP) and reading is mediated by phonological awareness (PA) in a normative sample of 615 eight-year-olds. TP was measured with auditory and bimodal (visual-auditory) temporal order judgment tasks and PA with a phoneme deletion task. PA partially mediated the association between both auditory and bimodal TP and reading, above nonverbal abilities, vocabulary, and processing speed. PA explained a larger proportion of the association between auditory TP and reading (56% vs. 39% for bimodal TP), and most of the association between bimodal TP and reading was direct. This finding is consistent with a dual-phonological and visual-pathway model of the association between TP and reading in normative reading skills. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1111/j.1467-8624.2012.01777.x
JN  - Child Development
VO  - 83
IP  - 4
PG  - 1332-1346
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc11&DO=10.1111%2fj.1467-8624.2012.01777.x

<43. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Future technology in cochlear implants: assessing the benefit. [References].
DP  - May 2011
YR  - 2011
LG  - English
AU  - Briggs, Robert J. S
SO  - Cochlear Implants International. Vol.12,(Suppl 1), 2011, pp. S22-S25. 
MO  - May
IS  - 1467-0100
IT  - 1754-7628
PT  - Journal
PT  - Peer Reviewed Journal
AB  - It has been over 50 years since Djourno and Eyries first attempted electric stimulation in a patient with deafness. Over this time, the Cochlear Implant (CI) has become not only remarkably successful, but increasingly complex. Although the basic components of the system still comprise an implanted receiver stimulator and electrode, externally worn speech processor, microphone, control system, and power source, there are now several alternative designs of these components with different attributes that can be variably combined to meet the needs of specific patient groups. Development by the manufacturers has been driven both by these various patient needs, and also by the desire to achieve technological superiority, or at least differentiation, ultimately in pursuit of market share. Assessment of benefit is the responsibility of clinicians. It is incumbent on both industry and clinicians to ensure appropriate, safe, and affordable introduction of new technology. For example, experience with the totally implanted cochlear implant (TIKI) has demonstrated that quality of hearing is the over-riding consideration for CI users. To date, improved hearing outcomes have been achieved by improvements in: speech processing strategies; microphone technology; pre-processing strategies; electrode placement; bilateral implantation; use of a hearing aid in the opposite ear (bimodal stimulation); and the combination of electric and acoustic stimulation in the same ear. The resulting expansion of CI candidacy, with more residual hearing, further improves the outcomes achieved. Largely facilitated by advances in electronic capability and computerization, it can be expected that these improvements will continue. However, marked variability of results still occurs and we cannot assure any individual patient of their outcome. Realistic goals for implementation of new technology include: improved hearing in noise and music perception; effective invisible hearing (no external apparatus); automated fitting; and reduction in outcome variability. This paper provides examples of relevant potential future technologies that can be applied to reach these goals. In the quest for better outcomes, future technology must deliver improved reliability and usability for both clinicians and recipients that does not compromise safety and is affordable. One of the challenges related to the introduction of new technologies is the 'classification' of CI systems and the framework under which sufficient change and increased benefit can be demonstrated to establish a claim of 'new generation CI' and hence increased reimbursement from third-party payers. Significant improvements in hearing outcomes and quality of life associated with CI design changes are difficult to measure, particularly when there is such dramatic benefit from the intervention of cochlear implantation from the individual's perspective. Manufacturers and clinicians need to be objective and undertake appropriate safety studies and long-term and multi-centre clinical trials to ensure that the introduction of new technology is both safe and effective and supported by health systems worldwide. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1179/146701011X13001035752291
JN  - Cochlear Implants International
VO  - 12
IP  - Suppl 1
PG  - S22-S25
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc10&DO=10.1179%2f146701011X13001035752291

<44. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Audiovisual integration of emotional signals from music improvisation does not depend on temporal correspondence. [References].
DP  - Apr 6, 2010
YR  - 2010
LG  - English
AU  - Petrini, Karin
AU  - McAleer, Phil
AU  - Pollick, Frank
SO  - Brain Research. Vol.1323, 2010, pp. 139-148. 
MO  - Apr
IS  - 0006-8993
IT  - 1872-6240
PT  - Journal
PT  - Peer Reviewed Journal
AB  - In the present study we applied a paradigm often used in face-voice affect perception to solo music improvisation to examine how the emotional valence of sound and gesture are integrated when perceiving an emotion. Three brief excerpts expressing emotion produced by a drummer and three by a saxophonist were selected. From these bimodal congruent displays the audio-only, visual-only, and audiovisually incongruent conditions (obtained by combining the two signals both within and between instruments) were derived. In Experiment 1 twenty musical novices judged the perceived emotion and rated the strength of each emotion. The results indicate that sound dominated the visual signal in the perception of affective expression, though this was more evident for the saxophone. In Experiment 2 a further sixteen musical novices were asked to either pay attention to the musicians' movements or to the sound when judging the perceived emotions. The results showed no effect of visual information when judging the sound. On the contrary, when judging the emotional content of the visual information, a worsening in performance was obtained for the incongruent condition that combined different emotional auditory and visual information for the same instrument. The effect of emotionally discordant information thus became evident only when the auditory and visual signals belonged to the same categorical event despite their temporal mismatch. This suggests that the integration of emotional information may be reinforced by its semantic attributes but might be independent from temporal features. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1016/j.brainres.2010.02.012
JN  - Brain Research
VO  - 1323
PG  - 139-148
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc9&DO=10.1016%2fj.brainres.2010.02.012

<45. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Users' experience of a cochlear implant combined with a hearing aid. [References].
DP  - Apr 2009
YR  - 2009
LG  - English
AU  - Fitzpatrick, Elizabeth Mary
AU  - Seguin, Christiane
AU  - Schramm, David
AU  - Chenier, Josee
AU  - Armstrong, Shelly
SO  - International Journal of Audiology. Vol.48,(4), 2009, pp. 172-182. 
MO  - Apr
IS  - 1499-2027
IT  - 1708-8186
PT  - Journal
PT  - Peer Reviewed Journal
AB  - This study examined (1) the prevalence of hearing-aid use in a clinical population of adults with unilateral cochlear implants, (2) the relationship between hearing aid use, seventy of hearing loss, duration of deafness and duration of cochlear implant use, and (3) the benefits of bimodal hearing from the users' perspective. Using a retrospective design, 31 adults were identified as bimodal users, and 93 adults implanted in the same period were identified as non hearing-aid users. The two groups were similar in regards to duration of deafness but differed in seventy of hearing loss and time since implantation Questionnaires examining frequency and situations of hearing-aid use were completed by 24 of 31 bimodal users Fifteen of these 24 adults reported hearing-aid use more than 50% of the time. These findings suggest that, of the 72 adults in this study with useable hearing (pure tone average better than 110 dB), about 30% or less regularly combined a hearing aid and cochlear implant. The questionnaire results suggest that regular bimodal users prefer bimodal hearing across a variety of listening environments such as music, noise, and reverberation. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1080/14992020802572619
JN  - International Journal of Audiology
VO  - 48
IP  - 4
PG  - 172-182
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc8&DO=10.1080%2f14992020802572619

<46. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Using bimodal stimulation to improve cochlear-implant performance.DP  - 2009
YR  - 2009
LG  - English
AU  - Cullington, Helen Elizabeth
SO  - Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.70,(2-B), 2009, pp. 924. 
IS  - 0419-4217
IB  - 978-1-109-03042-6
PT  - Dissertation Abstract
AB  - Cochlear implants have provided a sensation of hearing to hundreds of thousands of hearing-impaired people worldwide; adults with an implant can typically use the telephone, children with an implant can learn to speak and attend mainstream school. Although benefits can be remarkable in terms of speech recognition in quiet, some situations are still difficult for cochlear-implant users for example speech perception in noise, music appreciation, understanding tonal languages, tone of voice recognition, and talker identification. These tasks rely on pitch perception, which is generally poor in cochlear-implant users because of the speech processing algorithm. Amplitude envelope information is extracted from the incoming sound; the temporal fine structure is discarded. The fine structure is important for pitch perception. The current research evaluates the benefit afforded by a hearing aid worn on the opposite ear in conjunction with the cochlear implant in adults. This is termed bimodal hearing. A speech recognition task with competing talkers was developed, and tested on cochlear-implant users, normal-hearing people, and normal-hearing people listening through a cochlear-implant simulation (Chapter 2). The cochlear-implant users performed significantly worse than the normal-hearing listeners. In order to categorize the extent of residual hearing required for bimodal benefit, Chapter 3 used a unique cochlear-implant subject with normal hearing on the contralateral ear. The addition of low-frequency sound, even when unintelligible and limited to below 150 Hz, significantly improved cochlear-implant speech recognition with a competing talker. High-frequency sound did not improve performance. Bilateral cochlear implantation provides some benefit in terms of localization and speech recognition in noise, but it does not solve problems related to poor pitch discrimination. Chapter 4 compared thirteen bimodal and thirteen bilateral cochlear-implant users on speech recognition with a competing talker, music perception, tone of voice recognition, and talker identification. Although there was no significant difference in group mean scores between the bimodal and bilateral cochlear-implant users, examining data further showed an advantage for the bimodal users. The current research suggests that bimodal stimulation offers equal or better performance than bilateral cochlear implantation on the four tasks examined in adults. Bimodal stimulation should always be attempted before considering bilateral implantation. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
JN  - Dissertation Abstracts International: Section B: The Sciences and Engineering
VO  - 70
IP  - 2-B
PG  - 924
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc8&AN=2009-99160-001

<47. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Bimodal stimulation: Benefits for music perception and sound quality. [References].
DP  - 2009
YR  - 2009
LG  - English
AU  - Sucher, Catherine M
AU  - McDermott, Hugh J
SO  - Cochlear Implants International. Vol.10,(Suppl1), 2009, pp. 96-99. 
IS  - 1467-0100
IT  - 1754-7628
PT  - Journal
PT  - Peer Reviewed Journal
AB  - With recent expansions in cochlear implantation candidacy criteria, increasing numbers of implantees can exploit their remaining hearing by using bimodal stimulation (combining electrical stimulation via the implant with acoustic stimulation via hearing aids). This study examined the effect of bimodal stimulation on music perception and perceived sound quality. The perception of music and sound quality by nine post-lingually deafened adult implantees was examined in three conditions: implant alone, hearing aid alone and bimodal stimulation. On average, bimodal stimulation provided the best results for music perception and perceived sound quality when compared with results obtained with electrical stimulation alone. Thus, for implantees with usable acoustic hearing, bimodal stimulation may be advantageous when listening to music and other non-speech sounds. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1002/cii.398
JN  - Cochlear Implants International
VO  - 10
IP  - Suppl1
PG  - 96-99
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc8&DO=10.1002%2fcii.398

<48. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - The origins of language: Unraveling evolutionary forces.DP  - 2008
YR  - 2008
LG  - English
AU  - Masataka, Nobuo [Ed]
SO  - (2008). The origins of language: Unraveling evolutionary forces. viii, 157pp. New York, NY, US: Springer Science + Business Media; US. 
IB  - 978-4-431-79101-0 (Hardcover); 978-4-431-79102-7 (PDF)
PT  - Book
PT  - Edited Book
AB  - Developments in cognitive science indicate that human and nonhuman primates share a range of behavioral and physiological characteristics that speak to the issue of language origins. This volume has three major themes, woven throughout the chapters. First, it is argued that scientists in animal behavior and anthropology need to move beyond theoretical debate to a more empirically focused and comparative approach to language. Second, those empirical and comparative methods are described, revealing underpinnings of language, some of which are shared by humans and other primates and others of which are unique to humans. New insights are discussed, and several hypotheses emerge concerning the evolutionary forces that led to the "design" of language. Third, evolutionary challenges that led to adaptive changes in communication over time are considered with an eye toward understanding various constraints that channeled the process. This cross-disciplinary book will be of great interest to scientists who are interested in language, including linguists, biologists, psychologists, and anthropologists, as well as neuroscientists. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1007/978-4-431-79102-7
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc7&DO=10.1007%2f978-4-431-79102-7

<49. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Cross-modal interactions in the experience of musical performances: Physiological correlates. [References].
DP  - Sep 2008
YR  - 2008
LG  - English
AU  - Chapados, Catherine
AU  - Levitin, Daniel J
SO  - Cognition. Vol.108,(3), 2008, pp. 639-651. 
MO  - Sep
IS  - 0010-0277
IT  - 1873-7838
PT  - Journal
PT  - Peer Reviewed Journal
AB  - This experiment was conducted to investigate cross-modal interactions in the emotional experience of music listeners. Previous research showed that visual information present in a musical performance is rich in expressive content, and moderates the subjective emotional experience of a participant listening and/or observing musical stimuli [Vines, B. W., Krumhansl, C. L., Wanderley, M. M., & Levitin, D. J. (2006). Cross-modal interactions in the perception of musical performance. Cognition, 101, 80-113.]. The goal of this follow-up experiment was to replicate this cross-modal interaction by investigating the objective, physiological aspect of emotional response to music measuring electrodermal activity. The scaled average of electrodermal amplitude for visual-auditory presentation was found to be significantly higher than the sum of the reactions when the music was presented in visual only (VO) and auditory only (AO) conditions, suggesting the presence of an emergent property created by bimodal interaction. Functional data analysis revealed that electrodermal activity generally followed the same contour across modalities of presentation, except during rests (silent parts of the performance) when the visual information took on particular salience. Finally, electrodermal activity and subjective tension judgments were found to be most highly correlated in the audio-visual (AV) condition than in the unimodal conditions. The present study provides converging evidence for the importance of seeing musical performances, and preliminary evidence for the utility of electrodermal activity as an objective measure in studies of continuous music-elicited emotions. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1016/j.cognition.2008.05.008
JN  - Cognition
VO  - 108
IP  - 3
PG  - 639-651
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc7&DO=10.1016%2fj.cognition.2008.05.008

<50. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - The effects of music training and selective attention on working memory during bimodal processing of auditory and visual stimuli.DP  - 2007
YR  - 2007
LG  - English
AU  - Jones, Jennifer D
SO  - Dissertation Abstracts International Section A: Humanities and Social Sciences. Vol.67,(8-A), 2007, pp. 2805. 
IS  - 0419-4209
PT  - Dissertation Abstract
AB  - Researchers have investigated participants' abilities to recall various auditory and visual stimuli presented simultaneously during conditions of divided and selective attention. These investigations have rarely used actual music as the auditory stimuli. Music researchers have thoroughly investigated melodic recognition, but non-complimentary visual stimuli and attention conditions have rarely been applied during such studies. The purpose of this study was to examine the effects of music training and selective attention on recall of paired melodic and pictorial stimuli in a recognition memory paradigm. A total of 192 music and non-music majors viewed one of six researcher-prepared training videotapes containing eight images sequenced with a highly familiar music selection and an unfamiliar music selection under one of three attention conditions: divided attention, selective attention to music, and selective attention to pictures. A 24-question posttest presented bimodal test items that were paired during the training, paired distractors, a music trainer with a picture distractor, or a picture trainer with a music distractor. Total correct scores, error scores by modality, and scores by question type were obtained and analyzed. Results indicated that there were significant differences between music and non-music majors' recall of the bimodal stimuli under selective attention conditions. Music majors consistently outperformed non-music majors in divided attention and selective attention to music conditions, while non-music majors outperformed music majors during selective attention to pictures. Music majors were better able to reject distractor music than were non-music majors. Music majors made fewer music errors than non-music majors. However, an unanticipated effect of gender was found. Females were better at recognizing paired trainers and males were better at rejecting distractors for both music conditions. Individually selected memory strategies did not significantly impact total scores. Analyses of sample error rates to individual questions revealed memory effects for music due to serial position and rhythmic complexity of stimuli. Participants poorly recalled the final measure of both music conditions. This finding was unusual since this position is generally memorable in serial recall tasks. Simple rhythmic contexts were not remembered as well as more complex ones. The measures containing four quarter notes were not well recalled, even when tested two times. This study confirmed that selective attention protocols could be successfully applied to a melodic recognition paradigm with participants possessing various levels of music training. The effect of rhythmic complexity on memory requires further investigation, as does the effect of gender on recognition of melody. A better understanding of what makes a melody memorable would allow music educators and music therapists the opportunity to devise and teach effective strategies. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
JN  - Dissertation Abstracts International Section A: Humanities and Social Sciences
VO  - 67
IP  - 8-A
PG  - 2805
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc6&AN=2007-99003-035

<51. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - The feeling of familiarity of music and odors: The same neural signature? [References].
DP  - Nov 2007
YR  - 2007
LG  - English
AU  - Plailly, Jane
AU  - Tillmann, Barbara
AU  - Royet, Jean-Pierre
SO  - Cerebral Cortex. Vol.17,(11), 2007, pp. 2650-2658. 
MO  - Nov
IS  - 1047-3211
IT  - 1460-2199
PT  - Journal
PT  - Peer Reviewed Journal
AB  - The feeling of familiarity can be triggered by stimuli from all sensory modalities, suggesting a multimodal nature of its neural bases. In the present experiment, we investigated this hypothesis by studying the neural bases of familiarity processing of odors and music. In particular, we focused on familiarity referring to the participants' life experience. Items were classified as familiar or unfamiliar based on participants' individual responses, and activation patterns evoked by familiar items were compared with those evoked by unfamiliar items. For the feeling of familiarity, a bimodal activation pattern was observed in the left hemisphere, specifically the superior and inferior frontal gyri, the precuneus, the angular gyrus, the parahippocampal gyrus, and the hippocampus. Together with previously reported data on verbal items, visual items, and auditory items other than music, this outcome suggests a multimodal neural system of the feeling of familiarity. The feeling of unfamiliarity was related to a smaller bimodal activation pattern mainly located in the right insula and likely related to the detection of novelty. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1093/cercor/bhl173
JN  - Cerebral Cortex
VO  - 17
IP  - 11
PG  - 2650-2658
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc6&DO=10.1093%2fcercor%2fbhl173

<52. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Dichotomy and perceptual distortions in absolute pitch ability. [References].
DP  - Sep 2007
YR  - 2007
LG  - English
AU  - Athos, E. Alexandra
AU  - Levinson, Barbara
AU  - Kistler, Amy
AU  - Zemansky, Jason
AU  - Bostrom, Alan
AU  - Freimer, Nelson
AU  - Gitschier, Jane
SO  - PNAS Proceedings of the National Academy of Sciences of the United States of America. Vol.104,(37), 2007, pp. 14795-14800. 
MO  - Sep
IS  - 0027-8424
IT  - 1091-6490
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Absolute pitch (AP) is the rare ability to identify the pitch of a tone without the aid of a reference tone. Understanding both the nature and genesis of AP can provide insights into neuroplasticity in the auditory system. We explored factors that may influence the accuracy of pitch perception in AP subjects both during the development of the trait and in later age. We used a Web-based survey and a pitch-labeling test to collect perceptual data from 2,213 individuals, 981 (44%) of whom proved to have extraordinary pitch-naming ability. The bimodal distribution in pitch-naming ability signifies AP as a distinct perceptual trait, with possible implications for its genetic basis. The wealth of these data has allowed us to uncover unsuspected note-naming irregularities suggestive of a "perceptual magnet" centered at the note "A." In addition, we document a gradual decline in pitch-naming accuracy with age, characterized by a perceptual shift in the "sharp" direction. These findings speak both to the process of acquisition of AP and to its stability. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1073/pnas.0703868104
JN  - PNAS Proceedings of the National Academy of Sciences of the United States of America
VO  - 104
IP  - 37
PG  - 14795-14800
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc6&DO=10.1073%2fpnas.0703868104

<53. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Read my lips: An animated face helps communicate musical lyrics. [References].
DP  - Spr, 2007
YR  - 2007
LG  - English
AU  - Hidalgo-Barnes, Miguel
AU  - Massaro, Dominic W
SO  - Psychomusicology: A Journal of Research in Music Cognition. Vol.19,(2), 2007, pp. 3-12. 
MO  - Spr
IS  - 0275-3987
IT  - 2162-1535
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Understanding the lyrics of many songs, not just contemporary songs, is sometimes difficult. Watching the talker's face improves speech understanding when the speech is degraded by noise or by hearing difficulty. To explore whether the face can be similarly helpful in music, 34 phrases from the song "The Pressman" by Primus (1993) were played to thirteen college students. These phrases were aligned with Baldi, a computer-animated talking head. There were three presentation conditions: acoustic presentation of the lyrics, Baldi's mouthing of the lyrics, and the acoustic lyrics aligned with Baldi. For all three conditions, the students were asked to watch and listen and to immediately type the words they thought were being presented. Performance was significantly better in the bimodal condition than in the auditory condition, showing that visual information from the face contributes to the recognition of musical lyrics. Although the contribution of the face was significant, it was somewhat smaller than that found in speech. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1037/h0094037
JN  - Psychomusicology: A Journal of Research in Music Cognition
VO  - 19
IP  - 2
PG  - 3-12
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc6&DO=10.1037%2fh0094037

<54. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Complex courtship in a bimodal grasshopper hybrid zone. [References].
DP  - Jun 2003
YR  - 2003
LG  - English
AU  - Vedenina, V. Y
AU  - von Helversen, O
SO  - Behavioral Ecology and Sociobiology. Vol.54,(1), 2003, pp. 44-54. 
MO  - Jun
IS  - 0340-5443
IT  - 1432-0762
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Grasshoppers of the Chorthippus albomarginatus-group, which is outstanding with respect to its complex courtship song, were studied at fifteen localities in the Ukraine and Moldova. The analysis of the courtship songs revealed two species: C. albomarginatus in northeastern Ukraine and Chorthippus oschei in the southwestern Ukraine and Moldova. In a belt about 200 km wide, not only were one or the other pure species found, but also males with intermediate song characters. C. albomarginatus and C. oschei were hybridised in the laboratory, and F1 hybrid males as well as F2 hybrid males produced intermediate song patterns, quite similar to those recorded in the field. We defined a "hybrid song score" for intermediate songs. The score showed a bimodal distribution with most songs resembling one or other parental type, but with only a few intermediates. At several localities, where hybrids with songs similar to one of the parental species dominated, some individual males sang more similarly to the other species. We suggest that genetic introgression occurs between the two sibling species C. albomarginatus and C. oschei within a wide hybrid zone stretching over a distance of several hundred kilometres, but with a patchy spatial distribution. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1007/s00265-003-0595-2
JN  - Behavioral Ecology and Sociobiology
VO  - 54
IP  - 1
PG  - 44-54
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc4&DO=10.1007%2fs00265-003-0595-2

<55. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Intersensory redundancy guides attentional selectivity and perceptual learning in infancy. [References].
DP  - Mar 2000
YR  - 2000
LG  - English
AU  - Bahrick, Lorraine E
AU  - Lickliter, Robert
SO  - Developmental Psychology. Vol.36,(2), 2000, pp. 190-201. 
MO  - Mar
IS  - 0012-1649
IT  - 1939-0599
PT  - Journal
PT  - Peer Reviewed Journal
AB  - This study assessed an intersensory redundancy hypothesis, which holds that in early infancy information presented redundantly and in temporal synchrony across two sense modalities selectively recruits attention and facilitates perceptual differentiation more effectively than does the same information presented unimodally. Five-month-old infants' sensitivity to the amodal property of rhythm was examined in 3 experiments. Results revealed that habituation to a bimodal (auditory and visual) rhythm resulted in discrimination of a novel rhythm, whereas habituation to the same rhythm presented unimodally (auditory or visual) resulted in no evidence of discrimination. Also, temporal synchrony between the bimodal auditory and visual information was necessary for rhythm discrimination. These findings support an intersensory redundancy hypothesis and provide further evidence for the importance of redundancy for guiding and constraining early perceptual learning. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1037/0012-1649.36.2.190
JN  - Developmental Psychology
VO  - 36
IP  - 2
PG  - 190-201
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc3&DO=10.1037%2f0012-1649.36.2.190

<56. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Infants' response to the audible and visible properties of the human face: II. Discrimination of differences between singing and adult-directed speech.DP  - May 1998
YR  - 1998
LG  - English
AU  - Lewkowicz, David J
SO  - Developmental Psychobiology. Vol.32,(4), 1998, pp. 261-274. 
MO  - May
IS  - 0012-1630
IT  - 1098-2302
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Studied human infants' responsiveness to the audible and visible features of human faces by habituating them to a person speaking a prepared script in an adult-directed manner and then administering a series of separate test trials where a person could he seen, heard, or seen and heard singing. Ss included 32 Ss in each of 4 age groups of 3-, 4-, 6-, and 8-mo old infants. When habituated to a female person speaking in an adult directed manner and tested with a singing female 4, 6, and 8-mo-old infants responded to the audible, visible, and bimodal changes, whereas 3-mo-old infants only responded to the visual and bimodal changes. In contrast, when habituated to a male person speaking in an adult-directed manner and tested with a singing female, all age groups discriminated all 3 types of changes. Findings demonstrate that infants are responsive to differences between low- and high-prosody content inherent in both the facial and vocal characteristics of the human face and that, whereas responsiveness to the visible and bimodal features associated with differences between adult-directed speech and singing is present as early as 3 mo of age, responsiveness to the audible features emerges between 3 and 4 mo of age depending on whether gender differences are present as well. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1002/%28SICI%291098-2302%28199805%2932:4%3C261::AID-DEV1%3E3.0.CO;2-L
JN  - Developmental Psychobiology
VO  - 32
IP  - 4
PG  - 261-274
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc3&DO=10.1002%2f%2528SICI%25291098-2302%2528199805%252932%3a4%253C261%3a%3aAID-DEV1%253E3.0.CO%3b2-L

<57. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Interactions between auditory and visual processing when listening to music in an audiovisual context: 1. Matching 2. Audio quality. [References].
DP  - Spr-Fal, 1994
YR  - 1994
LG  - English
AU  - Iwamiya, Shin-ichiro
SO  - Psychomusicology: A Journal of Research in Music Cognition. Vol.13,(1-2), 1994, pp. 133-153. 
MO  - Spr-Fal
IS  - 0275-3987
IT  - 2162-1535
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Explored the effect of sound on the impression of video and the effect of video on the impression of sound. Two groups of 20 audiovisual excerpts, one each with matched or mismatched audio and visual contents, were used. In Exp 1, 9 Japanese acoustics design students rated audio and visual meaning on 22 scales in unimodal and bimodal contexts and the degree of matching of the audio and visual materials. For the higher-level factors of cleanness and uniqueness, audio meaning had a direct influence on visual meaning for matched excerpts. Consonance, where each modality psychologically affects the other in the same way, depends on the degree of matching for higher-order factors. In Exp 2, audio materials with and without degraded sound quality were rated unimodally and bimodally by 7 male Japanese acoustics design students. Results show that video presentation compensates for the negative effects of audio degradation independent of matching. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1037/h0094098
JN  - Psychomusicology: A Journal of Research in Music Cognition
VO  - 13
IP  - 1-2
PG  - 133-153
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc3&DO=10.1037%2fh0094098

<58. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Perception of the major/minor distinction: II. Experimental investigations. [References].
DP  - Spr-Fal, 1985
YR  - 1985
LG  - English
AU  - Crowder, Robert G
SO  - Psychomusicology: A Journal of Research in Music Cognition. Vol.5,(1-2), 1985, pp. 3-24. 
MO  - Spr-Fal
IS  - 0275-3987
IT  - 2162-1535
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Describes 4 experiments examining perception of the major/minor distinction in continua of sine-wave triads, varying in 9 equal steps from pure minor to pure major chords. Facility in labeling these items as major or minor was highly variable, bimodal in distribution among Ss, and only moderately related to musical experience. Same-different discrimination of these chords posed no particular problems for the Ss. Nearly all Ss heard 1st-inversion triads as sounding more major than root-position triads. Neighboring triads along a continuum were subject to contrastive context effects. This contrast seemed to have a sensory rather than cognitive basis. Triads otherwise capable of showing contrast were not effective when separated by an octave, an unexpected failure of octave generalization. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1037/h0094203
JN  - Psychomusicology: A Journal of Research in Music Cognition
VO  - 5
IP  - 1-2
PG  - 3-24
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc2&DO=10.1037%2fh0094203

<59. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Electronic graphs of musical performance: A pilot study in perception and learning.DP  - 1969
YR  - 1969
LG  - English
AU  - Heller, Jack J
SO  - Journal of Research in Music Education. Vol.17,(2), 1969, pp. 202-216. 
IS  - 0022-4294
IT  - 1945-0095
PT  - Journal
PT  - Peer Reviewed Journal
AB  - 12 freshmen (6 female voice majors, 4 violin majors, 2 trumpet majors) matched fundamental frequencies with significantly more accuracy when provided with continuous and immediate bimodal (visual and auditory) feedback than when given auditory feedback alone. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.2307/3344326
JN  - Journal of Research in Music Education
VO  - 17
IP  - 2
PG  - 202-216
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc2&DO=10.2307%2f3344326

<60. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - The measurement of one aspect of personality.DP  - 1947
YR  - 1947
LG  - English
AU  - Licht, Marie
SO  - The Journal of Psychology: Interdisciplinary and Applied. Vol.24, 1947, pp. 83-87. 
IS  - 0022-3980
IT  - 1940-1019
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Recent research indicates that aptitudes when completely isolated will prove to exist as Mendelian inherited characters which occur in pairs so that each individual shows either the dominant or the recessive trait of every pair. A word association test of 100 words given to 1000 persons and scored by a method based on significant responses yielded a bimodal curve of the type to be expected if the test distinguished between individuals possessing the dominant or the recessive trait of a pair. Subsequent validation showed that executives, teachers, politicians, etc., scored high, while researchers in all fields, artists, musicians, engineers, and writers scored low. The names objectivity and subjectivity respectively were assigned to the two groups since the common element seemed to be contact work versus individual work. A check of the shape of the curve on 5 different populations of 1000 cases each proved the reproducibility of the curve. Two other investigations are being made to contribute evidence to indicate the presence or absence of a Mendelian character in this test. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
DO  - https://dx.doi.org/10.1080/00223980.1947.9917341
JN  - The Journal of Psychology: Interdisciplinary and Applied
VO  - 24
PG  - 83-87
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc1&DO=10.1080%2f00223980.1947.9917341

<61. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - A qualitative systematic literature review of multimodal approaches for symptoms of dementia.DP  - 2024
YR  - 2024
LG  - English
AU  - Golston, Jeronda
SO  - Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.85,(6-B), 2024, pp. No Pagination Specified. 
IS  - 0419-4217
IB  - 979-8381113075
PT  - Dissertation Abstract
AB  - Dementia is a major challenge that individuals face in the 21st century. Over 115 million people will be affected by this disease in the next 30 years. The symptoms of dementia range from mild to severe and persistently deteriorate without appropriate treatment. This research explored the implementation of a multimodal approach to assist with dementia to support a better quality of life. Throughout this research, a comprehensive search was completed across several databases to obtain articles that met the criteria for inclusion. Participants from the 130 articles reviewed included people living with dementia and caregivers of all age groups, races, and levels of functioning. The data collected for this review included the use of various analysis tools such as the PRISMA-P. The researcher conducted a thematic analysis of multimodal approaches to assist with some of the common symptoms of dementia and cognition. Several authentic strategies for treating behavioral and psychological symptoms and preserving cognition in people with dementia were identified. Additional research in the field of psychophysiology is essential due to discoveries that link the body, brain, multiple mental processes, and dementia. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
JN  - Dissertation Abstracts International: Section B: The Sciences and Engineering
VO  - 85
IP  - 6-B
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc23&AN=2024-49607-065

<62. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Examining the effects of tempo in background music on adolescent learners' reading comprehension performance: Employing a multimodal approach. [References].
DP  - Feb 2024
YR  - 2024
LG  - English
AU  - Moreno, Matthew
AU  - Woodruff, Earl
SO  - Instructional Science. Vol.52,(1), 2024, pp. 71-88. 
MO  - Feb
IS  - 0020-4277
IT  - 1573-1952
PT  - Journal
PT  - Peer Reviewed Journal
AB  - This present study examines the psycho-emotional and psychophysiological effects that variations in the tempo of background music have on learners who are completing reading comprehension tests while being monitored used multi-modal computer technology. Results of seventy-four (N = 74) participants indicated that listening to fast tempo music (150 bpm) predicted lower reading comprehension scores, increased emotional expressions of fear, joy and contempt, and higher skin conductance responses (SCRs). Results indicated that participants were more likely to produce higher scores while listening to slow tempo music (110 bpm), but such findings were not connected to significant differences in facial emotion expressions or psychophysiological responses. Contrasting these were control/no-music conditions in which participants exhibited moderated scores. Results from the fast-tempo condition can possibly be attributed in part to an affective valence of emotions and psychophysiological responses, as the multimodal data suggests that a combined regulatory mechanism may be at play while engaged in a learning task. This paper raises several questions regarding the use and effects of background music in performance-based learning settings and the role of affective-stimuli on cognitive regulation. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
DO  - https://dx.doi.org/10.1007/s11251-023-09639-3
JN  - Instructional Science
VO  - 52
IP  - 1
PG  - 71-88
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1007%2fs11251-023-09639-3

<63. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Comparison of uni- and multimodal motion stimulation on visual neglect: A proof-of-concept study. [References].
DP  - Feb 2024
YR  - 2024
LG  - English
AU  - Geiser, Nora
AU  - Kaufmann, Brigitte Charlotte
AU  - Knobel, Samuel Elia Johannes
AU  - Cazzoli, Dario
AU  - Nef, Tobias
AU  - Nyffeler, Thomas
SO  - Cortex: A Journal Devoted to the Study of the Nervous System and Behavior. Vol.171, 2024, pp. 194-203. 
MO  - Feb
IS  - 0010-9452
IT  - 1973-8102
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Spatial neglect is characterized by the failure to attend stimuli presented in the contralesional space. Typically, the visual modality is more severely impaired than the auditory one. This dissociation offers the possibility of cross-modal interactions, whereby auditory stimuli may have beneficial effects on the visual modality. A new auditory motion stimulation method with music dynamically moving from the right to the left hemispace has recently been shown to improve visual neglect. The aim of the present study was twofold: a) to compare the effects of unimodal auditory against visual motion stimulation, i.e., smooth pursuit training, which is an established therapeutical approach in neglect therapy and b) to explore whether a combination of auditory + visual motion stimulation, i.e., multimodal motion stimulation, would be more effective than unimodal auditory or visual motion stimulation. 28 patients with left-sided neglect due to a first-ever, right-hemispheric subacute stroke were included. Patients either received auditory, visual, or multimodal motion stimulation. The between-group effect of each motion stimulation condition as well as a control group without motion stimulation was investigated by means of a one-way ANOVA with the patient's visual exploration behaviour as an outcome variable. Our results showed that unimodal auditory motion stimulation is equally effective as unimodal visual motion stimulation: both interventions significantly improved neglect compared to the control group. Multimodal motion stimulation also significantly improved neglect, however, did not show greater improvement than unimodal auditory or visual motion stimulation alone. Besides the established visual motion stimulation, this proof-of-concept study suggests that auditory motion stimulation seems to be an alternative promising therapeutic approach to improve visual attention in neglect patients. Multimodal motion stimulation does not lead to any additional therapeutic gain. In neurorehabilitation, the implementation of either auditory or visual motion stimulation seems therefore reasonable. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
DO  - https://dx.doi.org/10.1016/j.cortex.2023.10.018
JN  - Cortex: A Journal Devoted to the Study of the Nervous System and Behavior
VO  - 171
PG  - 194-203
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1016%2fj.cortex.2023.10.018

<64. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Multimodal acoustic-electric trigeminal nerve stimulation modulates conscious perception. [References].
DP  - Jan 2024
YR  - 2024
LG  - English
AU  - Wu, Min
AU  - Auksztulewicz, Ryszard
AU  - Riecke, Lars
SO  - NeuroImage. Vol.285, 2024, pp. 1-15.  ArtID 120476.
MO  - Jan
IS  - 1053-8119
IT  - 1095-9572
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Multimodal stimulation can reverse pathological neural activity and improve symptoms in neuropsychiatric diseases. Recent research shows that multimodal acoustic-electric trigeminal-nerve stimulation (TNS) (i.e., musical stimulation synchronized to electrical stimulation of the trigeminal nerve) can improve consciousness in patients with disorders of consciousness. However, the reliability and mechanism of this novel approach remain largely unknown. We explored the effects of multimodal acoustic-electric TNS in healthy human participants by assessing conscious perception before and after stimulation using behavioral and neural measures in tactile and auditory target-detection tasks. To explore the mechanisms underlying the putative effects of acoustic-electric stimulation, we fitted a biologically plausible neural network model to the neural data using dynamic causal modeling. We observed that (1) acoustic-electric stimulation improves conscious tactile perception without a concomitant change in auditory perception, (2) this improvement is caused by the interplay of the acoustic and electric stimulation rather than any of the unimodal stimulation alone, and (3) the effect of acoustic-electric stimulation on conscious perception correlates with inter-regional connection changes in a recurrent neural processing model. These results provide evidence that acoustic-electric TNS can promote conscious perception. Alterations in inter-regional cortical connections might be the mechanism by which acoustic-electric TNS achieves its consciousness benefits. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
DO  - https://dx.doi.org/10.1016/j.neuroimage.2023.120476
JN  - NeuroImage
VO  - 285
PG  - 1-15
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1016%2fj.neuroimage.2023.120476

<65. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Harbour seals use rhythmic percussive signalling in interaction and display. [References].
DP  - Jan 2024
YR  - 2024
LG  - English
AU  - Kocsis, Kinga
AU  - Duengen, Diandra
AU  - Jadoul, Yannick
AU  - Ravignani, Andrea
SO  - Animal Behaviour. Vol.207, 2024, pp. 223-234. 
MO  - Jan
IS  - 0003-3472
IT  - 1095-8282
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Multimodal rhythmic signalling abounds across animal taxa. Studying its mechanisms and functions can highlight adaptive components in highly complex rhythmic behaviours, like dance and music. Pinnipeds, such as the harbour seal, Phoca vitulina, are excellent comparative models to assess rhythmic capacities. Harbour seals engage in rhythmic percussive behaviours which, until now, have not been described in detail. In our study, eight zoo-housed harbour seals (two pups, two juveniles and four adults) were passively monitored by audio and video during their pupping/breeding season. All juvenile and adult animals performed percussive signalling with their fore flippers in agonistic conditions, both on land and in water. Flipper slap sequences produced on the ground or on the seals' bodies were often highly regular in their interval duration, that is, were quasi-isochronous, at a 200-600beats/min pace. Three animals also showed significant lateralization in slapping. In contrast to slapping on land, display slapping in water, performed only by adult males, showed slower tempo by one order of magnitude, and a rather motivic temporal structure. Our work highlights that percussive communication is a significant part of harbour seals' behavioural repertoire. We hypothesize that its forms of rhythm production may reflect adaptive functions such as regulating internal states and advertising individual traits. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
DO  - https://dx.doi.org/10.1016/j.anbehav.2023.09.014
JN  - Animal Behaviour
VO  - 207
PG  - 223-234
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1016%2fj.anbehav.2023.09.014

<66. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Disabling discourses: Contemporary cinematic representations of acquired physical disability. [References].
DP  - Jan-Feb 2024
YR  - 2024
LG  - English
AU  - Botha, Shawni
AU  - Harvey, Clare
SO  - Disability & Society. Vol.39,(1), 2024, pp. 62-84. 
MO  - Jan-Feb
IS  - 0968-7599
IT  - 1360-0508
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Film, a powerful publicising agent of knowledge, can have detrimental ideological and material implications contributing towards the systematic exclusion of disabled people. The paper explores how acquired physical disability is constructed within three contemporary mainstream fiction films. Guided by theoretical disability models and stereotypic representations of disability, identified by seminal authors in the field, the discussion highlights discourses that are perpetuated, challenged, or omitted within cinematic portrayals of disability. The paper also addresses how these discourses contribute to the maintenance or subversion of ableist power. The data underwent a multimodal analysis guided by critical and cinematic discourses. While steps towards more nuanced and diverse representations of acquired physical disability are evident, the films continue to perpetuate hegemonic discourses, emotionally provocative, and caricatured portrayals of disability. Arguably, contemporary disability fiction films are still largely produced for, and consumed by, abled audiences. Recommendations for transforming cinematic representations of the disabled are addressed. Points of interest: Films can communicate accurate knowledge as well as damaging stereotypes to the public. Disability has often been portrayed negatively in films and thus it is important to critically analyse films about disability.The paper discusses three contemporary films in which the main actors have an acquired physical disability. What is said about disability through the films' dialogue, and how disability is shown through camera angles, music, and props was analysed.The research found that films about acquired physical disability continue to produce negative stereotypes about disability. Thus, discrimination against disabled people is continued. Encouragingly, some stereotypes about disability were seen to be challenged in the contemporary films. Future films need to be more inclusive of disability. Characters need to be complex, all-rounded individuals, with disability being only one facet of their personhood. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
DO  - https://dx.doi.org/10.1080/09687599.2022.2060801
JN  - Disability & Society
VO  - 39
IP  - 1
PG  - 62-84
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc21&DO=10.1080%2f09687599.2022.2060801

<67. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Robots' "Woohoo" and "Argh" can enhance users' emotional and social perceptions: An exploratory study on non-lexical vocalizations and non-linguistic sounds. [References].
DP  - Dec 2023
YR  - 2023
LG  - English
AU  - Liu, Xiaozhen
AU  - Dong, Jiayuan
AU  - Jeon, Myounghoon
SO  - ACM Transactions of Human-Robot Interaction. Vol.12,(4), 2023, pp. 1-20.  ArtID 54.
MO  - Dec
IT  - 2573-9522
PT  - Journal
PT  - Peer Reviewed Journal
AB  - As robots have become more pervasive in our everyday life, social aspects of robots have attracted researchers' attention. Because emotions play a crucial role in social interactions, research has been conducted on conveying emotions via speech. Our study sought to investigate the synchronization of multimodal interaction in human-robot interaction (HRI). We conducted a within-subjects exploratory study with 40 participants to investigate the effects of non-speech sounds (natural voice, synthesized voice, musical sound, and no sound) and basic emotions (anger, fear, happiness, sadness, and surprise) on user perception with emotional body gestures of an anthropomorphic robot (Pepper). While listening to a fairytale with the participant, a humanoid robot responded to the story with recorded emotional non-speech sounds and gestures. Participants showed significantly higher emotion recognition accuracy from the natural voice than from other sounds. The confusion matrix showed that happiness and sadness had the highest emotion recognition accuracy, which is in line with previous research. The natural voice also induced higher trust, naturalness, and preference compared to other sounds. Interestingly, the musical sound mostly showed lower perception ratings, even compared to no sound. Results are discussed with design guidelines for emotional cues from social robots and future research directions. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
DO  - https://dx.doi.org/10.1145/3626185
JN  - ACM Transactions of Human-Robot Interaction
VO  - 12
IP  - 4
PG  - 1-20
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc23&DO=10.1145%2f3626185

<68. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Nonverbal sound in human-robot interaction: A systematic review. [References].
DP  - Dec 2023
YR  - 2023
LG  - English
AU  - Zhang, Brian J
AU  - Fitter, Naomi T
SO  - ACM Transactions of Human-Robot Interaction. Vol.12,(4), 2023, pp. 1-46.  ArtID 46.
MO  - Dec
IT  - 2573-9522
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Nonverbal sound offers great potential to enhance robots' interactions with humans, and a growing body of research has begun to explore nonverbal sound for tasks such as sound source localization, explicit communication, and improving sociability. However, nonverbal sound has a broad interpretation and design space that can draw from areas such as machine learning, music theory, and foley. We sought to identify and compare use cases and approaches for nonverbal sound in human-robot interaction through a systematic review. A search of sound and robotics-related publisher databases yielded 148 peer-reviewed articles presenting systems, studies, and taxonomies. Differences in taxonomy and overlap of terminology with adjacent research fields such as speech, gaze, and gesture posed difficulties for the search, which we attempted to address through a multi-stage search process. Based on the reviewed articles, we developed a pair of taxonomies using scientific communication principles and analyzed study designs and measures for the creation of nonverbal robot sound. We discuss recommendations for the field, including the use of the new taxonomies; methods for design, generation, and validation; and paths for future research. Roboticists may benefit from incorporating nonverbal sound as a key component in multimodal human-robot interaction. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
JN  - ACM Transactions of Human-Robot Interaction
VO  - 12
IP  - 4
PG  - 1-46
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc23&AN=2024-47330-006

<69. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Self-perception and anticipated efficacy of the anti-dementia multimodal program in 100 older adults with mild cognitive impairment. [References].
DP  - 2023
YR  - 2023
LG  - English
AU  - Oh, Wonjun
AU  - Kim, Tae Hui
AU  - You, Joshua (Sung) H
SO  - NeuroRehabilitation. Vol.52,(3), 2023, pp. 403-412. 
IS  - 1053-8135
IT  - 1878-6448
PT  - Journal
PT  - Peer Reviewed Journal
AB  - The article presents a study on the self-perception and anticipated efficacy of the anti-dementia multimodal program in 100 older adults with mild cognitive impairment. Effective and sustainable interventions are clearly needed for mild cognitive impairment (MCI) patients. Despite the clinical importance of the multimodal intervention approach, only one study using a multimodal approach demonstrated promising improvements in memory, attention, and executive functions, which also correlated with functional magnetic resonance imaging (MRI) blood oxygenation level dependent (BOLD) changes in cerebral activation in 50 MCI patients. To investigate the self-perception and anticipated efficacy of each element of the BRAIN-FIT multimodal intervention program (robotic-assisted gait training (RAGT), computerized cognitive therapy, music, light, transcranial direct current stimulation (tDCS), and diaphragmatic breathing exercises) and the correlation between memory, concentration, depression, and sleep in older adults with MCI. One hundred participants (mean+/-standard deviation: 8.63+/-78.4 years; 47 women) with MCI were recruited from a major university medical center and community dementia relief center. The survey questionnaire comprised four domains with 21 questions, including four pertaining to general demographic characteristics, eight related to exercise and activity, three related to sleep, and nine related to the BRAIN-FIT program. Chi-squared testwas used to analyze the Likert scale data. The descriptive frequencies were calculated. Additionally, Spearman's rho statistics measure the rank-order association. The statistical significance was at P < 0.05. The present study's results provide clinical evidence-based insights into the utilization of BRAIN-FIT in MCI to maximize cognitive score improvement of memory, concentration, depression, and sleep. Therefore, when designing the BRAIN-FIT, six intervention items were set in proportion to the preference based on the survey, to reduce participants' feeling of repulsion. The program was configured according to exercise intensity. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
JN  - NeuroRehabilitation
VO  - 52
IP  - 3
PG  - 403-412
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc23&AN=2024-61168-004

<70. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Soundscapes of morality: Linking music preferences and moral values through lyrics and audio. [References].
DP  - Nov 29, 2023
YR  - 2023
LG  - English
AU  - Preniqi, Vjosa
AU  - Kalimeri, Kyriaki
AU  - Saitis, Charalampos
SO  - PLoS ONE. Vol.18,(11), 2023, ArtID e0294402.
MO  - Nov
IT  - 1932-6203
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Music is a fundamental element in every culture, serving as a universal means of expressing our emotions, feelings, and beliefs. This work investigates the link between our moral values and musical choices through lyrics and audio analyses. We align the psychometric scores of 1,480 participants to acoustics and lyrics features obtained from the top 5 songs of their preferred music artists from Facebook Page Likes. We employ a variety of lyric text processing techniques, including lexicon-based approaches and BERT-based embeddings, to identify each song's narrative, moral valence, attitude, and emotions. In addition, we extract both low- and high-level audio features to comprehend the encoded information in participants' musical choices and improve the moral inferences. We propose a Machine Learning approach and assess the predictive power of lyrical and acoustic features separately and in a multimodal framework for predicting moral values. Results indicate that lyrics and audio features from the artists people like inform us about their morality. Though the most predictive features vary per moral value, the models that utilised a combination of lyrics and audio characteristics were the most successful in predicting moral values, outperforming the models that only used basic features such as user demographics, the popularity of the artists, and the number of likes per user. Audio features boosted the accuracy in the prediction of empathy and equality compared to textual features, while the opposite happened for hierarchy and tradition, where higher prediction scores were driven by lyrical features. This demonstrates the importance of both lyrics and audio features in capturing moral values. The insights gained from our study have a broad range of potential uses, including customising the music experience to meet individual needs, music rehabilitation, or even effective communication campaign crafting. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
DO  - https://dx.doi.org/10.1371/journal.pone.0294402
JN  - PLoS ONE
VO  - 18
IP  - 11
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc23&DO=10.1371%2fjournal.pone.0294402

<71. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - The architecture of abnormal reward behaviour in dementia: Multimodal hedonic phenotypes and brain substrate. [References].
DP  - Feb 9, 2023
YR  - 2023
LG  - English
AU  - Chokesuwattanaskul, Anthipa
AU  - Jiang, Harmony
AU  - Bond, Rebecca L
AU  - Jimenez, Daniel A
AU  - Russell, Lucy L
AU  - Sivasathiaseelan, Harri
AU  - Johnson, Jeremy C. S
AU  - Benhamou, Elia
AU  - Agustus, Jennifer L
AU  - van Leeuwen, Janneke E. P
AU  - Chokesuwattanaskul, Peerapat
AU  - Hardy, Chris J . D
AU  - Marshall, Charles R
AU  - Rohrer, Jonathan D
AU  - Warren, Jason D
SO  - Brain Communications. Vol.5,(2), 2023, ArtID fcad027.
MO  - Feb
IT  - 2632-1297
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Abnormal reward processing is a hallmark of neurodegenerative diseases, most strikingly in frontotemporal dementia. However, the phenotypic repertoire and neuroanatomical substrates of abnormal reward behaviour in these diseases remain incompletely characterized and poorly understood. Here we addressed these issues in a large, intensively phenotyped patient cohort representing all major syndromes of sporadic frontotemporal dementia and Alzheimer's disease. We studied 27 patients with behavioural variant frontotemporal dementia, 58 with primary progressive aphasia (22 semantic variant, 24 non-fluent/agrammatic variant and 12 logopenic) and 34 with typical amnestic Alzheimer's disease, in relation to 42 healthy older individuals. Changes in behavioural responsiveness were assessed for canonical primary rewards (appetite, sweet tooth, sexual activity) and non-primary rewards (music, religion, art, colours), using a semi-structured survey completed by patients' primary caregivers. Changes in more general socio-emotional behaviours were also recorded. We applied multiple correspondence analysis and k-means clustering to map relationships between hedonic domains and extract core factors defining aberrant hedonic phenotypes. Neuroanatomical associations were assessed using voxel-based morphometry of brain MRI images across the combined patient cohort. Altered (increased and/or decreased) reward responsiveness was exhibited by most patients in the behavioural and semantic variants of frontotemporal dementia and around two-thirds of patients in other dementia groups, significantly (P < 0.05) more frequently than in healthy controls. While food-directed changes were most prevalent across the patient cohort, behavioural changes directed toward non-primary rewards occurred significantly more frequently (P < 0.05) in the behavioural and semantic variants of frontotemporal dementia than in other patient groups. Hedonic behavioural changes across the patient cohort were underpinned by two principal factors: a 'gating' factor determining the emergence of altered reward behaviour and a 'modulatory' factor determining how that behaviour is directed. These factors were expressed jointly in a set of four core, trans-diagnostic and multimodal hedonic phenotypes: 'reward-seeking', 'reward-restricted', 'eating-predominant' and 'control-like'-variably represented across the cohort and associated with more pervasive socio-emotional behavioural abnormalities. The principal gating factor was associated (P < 0.05 after correction for multiple voxel-wise comparisons over the whole brain) with a common profile of grey matter atrophy in anterior cingulate, bilateral temporal poles, right middle frontal and fusiform gyri: the cortical circuitry that mediates behavioural salience and semantic and affective appraisal of sensory stimuli. Our findings define a multi-domain phenotypic architecture for aberrant reward behaviours in major dementias, with novel implications for the neurobiological understanding and clinical management of these diseases. Chokesuwattanaskul et al. define four trans-diagnostic, multimodal phenotypes of reward behaviour in Alzheimer's and frontotemporal dementias. Two core factors drive the emergence and direction of behaviours, with a neural substrate in frontotemporal circuitry that codes the salience and semantic value of sensory objects. See Horne and Irish (https://doi.org/10.1093/braincomms/fcad045) for a scientific commentary on this article. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
DO  - https://dx.doi.org/10.1093/braincomms/fcad027
JN  - Brain Communications
VO  - 5
IP  - 2
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1093%2fbraincomms%2ffcad027

<72. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - A Synopsis of music based interventions in MusicMedicine: Definitions, standards, research, applications, with special emphasis on anxiety, pain and stress. [References].
DP  - Oct 2023
YR  - 2023
LG  - English
AU  - Spintge, Ralph
SO  - Music and Medicine. Vol.15,(4), 2023, pp. 201-206. 
MO  - Oct
IS  - 1943-8621
IT  - 1943-863X
PT  - Journal
PT  - Peer Reviewed Journal
AB  - MusicMedicine describes the use of medicofunctional music, today called music-based interventions, promoting therapeutic benefits in medical settings based on scientific evidence. In prevention, therapy, rehabilitation, health promotion, performance enhancement, behavioral management and many other settings its benefits may at the same time contribute to cost containment. Established standards in education, research, and application secure reliability, validity and reproducibility of methods, concepts, results and therapeutic effects. Such standards include definition of intervening variables such as the musical stimuli used, as well as contributing or interfering variables, such as specific clinical settings or sociocultural background. Wherever possible, studies and therapeutic regimes should include music therapists. Traditionally, educated doctors know much about medicine, and might be fond of music, but usually have no music therapeutic expertise. At the same time, research in MusicMedicine demands interdisciplinary and multimodal approaches using mixed-methods design with thorough biostatistical design and analysis. Since 1982, MusicMedicine as inaugurated by the International Society for Music in Medicine ISMM e.V. has bridged together music therapy and traditional medical science orientations, leading towards a solid partnership that is influencing today's practice of integrative medicine. Publications of studies about music-based medical interventions should preferably include an audio-file of the music used in the conducted session. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
DO  - https://dx.doi.org/10.47513/mmd.v15i4.966
JN  - Music and Medicine
VO  - 15
IP  - 4
PG  - 201-206
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.47513%2fmmd.v15i4.966

<73. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - When the painting meets its musical inspiration: The impact of multimodal art experience on aesthetic enjoyment and subjective well-being in the museum. [References].
DP  - Dec 14, 2023
YR  - 2023
LG  - English
AU  - Fekete, Anna
AU  - Specker, Eva
AU  - Mikuni, Jan
AU  - Trupp, MacKenzie D
AU  - Leder, Helmut
SO  - Psychology of Aesthetics, Creativity, and the Arts. 2023, pp. No Pagination Specified. 
MO  - Dec
IS  - 1931-3896
IT  - 1931-390X
PT  - Journal
PT  - Peer Reviewed Journal
AB  - It is assumed that multimodal experiences of art (e.g., listening to music while viewing a painting) can improve aesthetic experience as the two modalities can complement each other. In the current museum study, we tested whether the multimodal experience of works of art-where the artwork is inspired by the musical piece-can enhance aesthetic experience, leading to better well-being benefits. For this, we used a mixed design to compare people who viewed Klimt's Beethoven Frieze painting in the Secession Museum (Vienna, Austria) either on its own (n = 111) or while listening to its musical inspiration (n = 129), excerpts of Beethoven's Ninth Symphony. For all visitors, a short museum visit (M = 14.3, SD = 6.6 min) reduced anxiety, stress, and negative mood, as well as improved positive mood. Furthermore, this effect was larger for those who also heard the music and perceived it as pleasant and congruent with the artwork. Additionally, these two factors slightly enhanced aesthetic experience and made people less distracted by the other things, and resulted in longer viewing times. Finally, those who knew more about art, who were more interested in art, or more aesthetically responsive enjoyed the art more, understood it better, and their mood improved more in the museum. Overall, our results highlight the role of subjective experience and indicate that qualitatively better art experiences lead to higher well-being gains. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1037/aca0000641
JN  - Psychology of Aesthetics, Creativity, and the Arts
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1037%2faca0000641

<74. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Collecting Mementos: A multimodal dataset for context-sensitive modeling of affect and memory processing in responses to videos. [References].
DP  - Apr-Jun 2023
YR  - 2023
LG  - English
AU  - Dudzik, Bernd
AU  - Hung, Hayley
AU  - Neerincx, Mark
AU  - Broekens, Joost
SO  - IEEE Transactions on Affective Computing. Vol.14,(2), 2023, pp. 1249-1266. 
MO  - Apr-Jun
IT  - 1949-3045
PT  - Journal
PT  - Peer Reviewed Journal
AB  - In this article we introduce Mementos: the first multimodal corpus for computational modeling of affect and memory processing in response to video content. It was collected online via crowdsourcing and captures 1995 individual responses collected from 297 unique viewers responding to 42 different segments of music videos. Apart from webcam recordings of their upper-body behavior (totaling 2012 minutes) and self-reports of their emotional experience, it contains detailed descriptions of the occurrence and content of 989 personal memories triggered by the video content. Finally, the dataset includes self-report measures related to individual differences in participants' background and situation (Demographics, Personality, and Mood), thereby facilitating the exploration of important contextual factors in research using the dataset. We describe 1) the construction and contents of the corpus itself, 2) analyse the validity of its content by investigating biases and consistency with existing research on affect and memory processing, 3) review previously published work that demonstrates the usefulness of the multimodal data in the corpus for research on automated detection and prediction tasks, and 4) provide suggestions for how the dataset can be used in future research on modeling Video-Induced Emotions, Memory-Associated Affect, and Memory Evocation. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1109/TAFFC.2021.3089584
JN  - IEEE Transactions on Affective Computing
VO  - 14
IP  - 2
PG  - 1249-1266
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1109%2fTAFFC.2021.3089584

<75. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Words and music: Creating transformative opportunities through implicit and explicit dialogue. [References].
DP  - Jul-Sep 2023
YR  - 2023
LG  - English
AU  - Davis, Scott M
SO  - Psychoanalysis, Self and Context. Vol.18,(4), 2023, pp. 618-629. 
MO  - Jul-Sep
IS  - 2472-0038
IT  - 2472-0046
PT  - Journal
PT  - Peer Reviewed Journal
AB  - While psychoanalysis historically privileged the mutative power of spoken words and explicit interpretive understanding, we now know that all experience originates in, unfolds from and is felt through our bodies, enhancing or constraining what can be talked about explicitly. The therapist optimally expands her listening perspective to include implicit communications of bodily experience in order to deepen the empathic process and create new therapeutic opportunity. Principles from infant research, neurobiology, progressive establishment of a collaborative, contingent dialogue and sustaining an intention unfolding process inform the integrative approach illustrated in this paper. Psychoanalysis is a process of learning by doing a multimodal fitting together process through dialogue that is continuously implicit and intermittently verbal. The analyst must actively facilitate and scaffold implicit and explicit dialogue with the goal of fitting together and creating new experience. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1080/24720038.2023.2224408
JN  - Psychoanalysis, Self and Context
VO  - 18
IP  - 4
PG  - 618-629
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1080%2f24720038.2023.2224408

<76. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Snapshots from the music therapy treatment of a 10-year-old boy with encopresis. A case study. [German]. [References].
OT  - Momentaufnahmen aus der musiktherapeutischen Behandlung eines 10-jahrigen Jungen mit Enkopresis: Eine Fallstudie.
DP  - Jul 2023
YR  - 2023
LG  - German
AU  - Grandke, Viola
AU  - Reuter, Laurence
AU  - Grandke, Emma Luise
AU  - Bauer, Susanne
SO  - Die Psychotherapie. Vol.68,(4), 2023, pp. 296-301. 
MO  - Jul
IS  - 2731-7161
IT  - 2731-717X
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Excerpts from an in-patient course of music therapy are presented in the context of a multimodal holistic treatment approach. The case study of a 10-year-old boy suffering from encopresis since the age of 6 years is used to illustrate how music therapy can complement standard clinical treatment. Sessions took place in individual and selective family settings. The focus of the music therapy treatment was on the psychosocial abnormalities underlying the dominant symptomatology and the interactional family problems. The paper focuses on those aspects of treatment that reveal a change in the relational experience. This simultaneously includes aspects of the interpersonal relationship between father and son during playing and the study of the intrapsychic dimension in terms of self-experience and resonance in the presence of another person. During the treatment the father succeeded in performing a more sensitized interaction with his son, which supported the son's progressive development in terms of formation of autonomy and control as well as an improved capacity for expression. (PsycInfo Database Record (c) 2023 APA, all rights reserved)

      Abstract (German)
      Vorgestellt werden Ausschnitte eines stationaren Musiktherapieverlaufes im Rahmen eines multimodalen ganzheitlichen Behandlungsansatzes. Anhand der Kasuistik eines 10-jahrigen Patienten, der seit seinem 6. LJ unter Enkopresis leidet, wird exemplarisch dargestellt, in welcher Weise Musiktherapie die klinische Standardbehandlung erganzen kann. Es fanden Sitzungen im Einzel- und im selektiven Familiensetting statt. Im Fokus der musiktherapeutischen Behandlung standen die der dominanten Symptomatik zugrunde liegenden psychosozialen Auffalligkeiten und die interaktionelle familiare Problematik. Der Beitrag fokussiert jene Behandlungsaspekte, die eine Veranderung des Beziehungserlebens sichtbar werden lassen. Dazu zahlen sowohl die interpersonellen Beziehungsaspekte zwischen Vater und Sohn wahrend des Spielens als auch die intrapsychischen Anteile im Sinne des Selbsterlebens und der Resonanz in Gegenwart eines anderen. Im Verlauf der Behandlung gelang dem Vater ein sensibilisierterer Umgang mit seinem Sohn, was die progressive Entwicklung des Sohnes hinsichtlich der Ausbildung von Autonomie und Kontrolle sowie eines verbesserten Ausdrucksvermogens unterstutzte. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1007/s00278-023-00663-9
JN  - Die Psychotherapie
VO  - 68
IP  - 4
PG  - 296-301
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1007%2fs00278-023-00663-9

<77. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - The impact of visual display of human motion on observers' perception of music performance. [References].
DP  - Mar 8, 2023
YR  - 2023
LG  - English
AU  - Moura, Nadia
AU  - Fonseca, Pedro
AU  - Goethel, Marcio
AU  - Oliveira-Silva, Patricia
AU  - Vilas-Boas, Joao Paulo
AU  - Serra, Sofia
SO  - PLoS ONE. Vol.18,(3), 2023, ArtID e0281755.
MO  - Mar
IT  - 1932-6203
PT  - Journal
PT  - Peer Reviewed Journal
AB  - In investigating the influence of body movement in multimodal perception, human motion displays are frequently used as a means of visual standardization and control of external confounders. However, no principle is established regarding the selection of an adequate display for specific study purposes. The aim of this study was to evaluate the effects of adopting 4 visual displays (point-light, stick figure, body mass, skeleton) on the observers' perception of music performances in 2 expressive conditions (immobile, projected expressiveness). Two hundred eleven participants rated 8 audio-visual samples in expressiveness, match between movement and music, and overall evaluation. The results revealed significant isolated main effects of visual display and expressive condition on the observers' ratings (in both, p < 0.001), and interaction effects between the two factors (p < 0.001). Displays closer to a human form (mostly skeleton, sometimes body mass) exponentiated the evaluations of expressiveness and music-movement match in the projected expressiveness condition, and of overall evaluation in the immobile condition; the opposite trend occurred with the simplified motion display (stick figure). Projected expressiveness performances were higher rated than immobile performances. Although the expressive conditions remained distinguishable across displays, the more complex ones potentiated the attribution of subjective qualities. We underline the importance of considering the variable display as an influencing factor in perceptual studies. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1371/journal.pone.0281755
JN  - PLoS ONE
VO  - 18
IP  - 3
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1371%2fjournal.pone.0281755

<78. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Multimodal quantitative magnetic resonance imaging of the thalamus in tinnitus patients with different outcomes after sound therapy. [References].
DP  - Dec 2023
YR  - 2023
LG  - English
AU  - Chen, Qian
AU  - Lv, Han
AU  - Wang, Zhaodi
AU  - Li, Xiaoshuai
AU  - Wang, Xinghao
AU  - Huang, Yuyou
AU  - Zhao, Pengfei
AU  - Yang, Zhenghan
AU  - Gong, Shusheng
AU  - Wang, Zhenchang
SO  - CNS Neuroscience & Therapeutics. Vol.29,(12), 2023, pp. 4070-4081. 
MO  - Dec
IS  - 1755-5930
IT  - 1755-5949
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Aims This study systematically investigated structural and functional alterations in the thalamus and its subregions using multimodal magnetic resonance imaging (MRI) and examined its clinical relevance in tinnitus patients with different outcomes after sound therapy (narrowband noise). Methods In total, 60 patients with persistent tinnitus and 57 healthy controls (HCs) were recruited. Based on treatment efficacy, 28 patients were categorized into the effective group and 32 into the ineffective group. Five MRI measurements of the thalamus and its seven subregions, including gray matter volume, fractional anisotropy, fractional amplitude of low-frequency fluctuation, and functional connectivity (FC), were obtained for each participant and compared between the groups. Results Patients in both the groups exhibited widespread functional and diffusion abnormalities in the whole thalamus and several subregions, with more obvious changes observed in the effective group. All tinnitus patients had abnormal FC compared with the HCs; FC differences between the two patient groups were only observed in the striatal network, auditory-related cortex, and the core area of the limbic system. We combined the multimodal quantitative thalamic alterations and used it as an imaging indicator to evaluate prognosis before sound therapy and achieved a sensitivity of 71.9% and a specificity of 85.7%. Conclusion Similar patterns of thalamic alterations were identified in tinnitus patients with different outcomes, with more obvious changes observed in the effective group. Our findings support the tinnitus generation hypothesis of frontostriatal gating system dysfunction. A combination of multimodal quantitative thalamic properties may be used as indicators to predict tinnitus prognosis before sound therapy. This study systematically investigated structural and functional alterations in the thalamus and its subregions using multimodal MRI properties, including gray matter volume, fractional anisotropy, fractional amplitude of low-frequency fluctuation, and functional connectivity, and examined its clinical relevance in tinnitus patients with different outcomes after sound therapy. We found that similar patterns of thalamic alterations were identified in tinnitus patients with different outcomes, with more obvious changes observed in the effective group. Moreover, our findings support the tinnitus generation hypothesis of frontostriatal gating system dysfunction. A combination of multimodal quantitative thalamic properties may be used as indicators to predict tinnitus prognosis before sound therapy. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1111/cns.14330
JN  - CNS Neuroscience & Therapeutics
VO  - 29
IP  - 12
PG  - 4070-4081
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1111%2fcns.14330

<79. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Feasibility and acceptability of a group music creativity intervention for adults with varying cognitive function. [References].
DP  - Nov 5, 2023
YR  - 2023
AU  - Wu-Chung, E. Lydia
AU  - Brandt, Anthony K
AU  - Bonomo, Melia E
AU  - Denny, Bryan T
AU  - Karmonik, Christof
AU  - Frazier, J. Todd
AU  - Blench, Karl
AU  - Fagundes, Christopher P
SO  - Creativity Research Journal. 2023, pp. No Pagination Specified. 
MO  - Nov
IS  - 1040-0419
IT  - 1532-6934
PT  - Journal
PT  - Peer Reviewed Journal
AB  - ABSTRACT Maintaining healthy cognitive functioning and delaying cognitive decline in cognitively intact and cognitively impaired adults are major research initiatives for addressing dementia disease burden. Music interventions are promising, non-pharmaceutical treatment options for preserving cognitive function and psychological health in older adults with varying levels of cognitive function. While passive, music interventions have attracted considerable attention in the abnormal cognitive aging literature, active, music interventions such as music creativity are less well-studied. Among 58 older adults with different levels of cognitive function (cognitively healthy to mild cognitive impairment), we examined the feasibility and acceptability of Project CHROMA, a Stage 1 clinical trial developed to assess the effects of a novel, music creativity curriculum on various health outcomes. Music intervention participation (93%), overall study retention (78%), and intervention satisfaction (100%) rates were comparable to other similarly designed clinical trials. Exploratory analyses using mixed-level modeling tested the efficacy of the intervention on cognitive and psychological outcomes. Compared to those in the control condition, participants in the music condition showed some improvements in cognitive functioning and socioemotional well-being. Findings suggest that a 6-week music creativity clinical trial with several multi-modal health assessments can be feasibly implemented within a sample of varying cognitive ability. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1080/10400419.2023.2272105
JN  - Creativity Research Journal
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1080%2f10400419.2023.2272105

<80. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Improvised herding: Mapping biobehavioral mechanisms that underlie group efficacy during improvised social interaction. [References].
DP  - Sep 2023
YR  - 2023
LG  - English
AU  - Greenberg, David M
AU  - Milstein, Nir
AU  - Gilboa, Avi
AU  - Cohen, Shai
AU  - Haimovich, Nir
AU  - Siegman, Shahar
AU  - Pinhasi, Shay
AU  - Gordon, Ilanit
SO  - Psychophysiology. Vol.60,(9), 2023, pp. No Pagination Specified.  ArtID e14307.
MO  - Sep
IS  - 0048-5772
IT  - 1469-8986
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Improvisation is a natural occurring phenomenon that is central to social interaction. Yet, improvisation is an understudied area in group processes and intergroup relations. Here we build on theory and research about human herding to study the contributions of improvisation on group efficacy and its biobehavioral underpinnings. We employed a novel multimodal approach and integrative method when observing face-to-face interactions-51 triads (total N = 153) drummed together in spontaneous-free improvisations as a group, while their electrodermal activity was monitored simultaneously with their second-by-second rhythmic coordination on a shared electronic drum machine. Our results show that three hypothesized factors of human herding-physiological synchrony, behavioral coordination, and emotional contagion-predict a sense of group efficacy in its group members. These findings are some of the first to show herding at three levels (physiological, behavioral, and mental) in a single study and lay a basis for understanding the role of improvisation in social interaction. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1111/psyp.14307
JN  - Psychophysiology
VO  - 60
IP  - 9
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1111%2fpsyp.14307

<81. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - The effect of ear-training approach on music-evoked emotions and music liking. [References].
DP  - Apr 2023
YR  - 2023
LG  - English
AU  - Zauhar, Valnea
AU  - Vidulin, Sabina
AU  - Plavsic, Marlena
AU  - Bajsanski, Igor
SO  - Psihologijske Teme. Vol.32,(1), 2023, pp. 81-104. 
MO  - Apr
IS  - 1332-0742
IT  - 1849-0395
PT  - Journal
PT  - Peer Reviewed Journal
AB  - In this study, we examined differences in music-evoked emotions and music liking between two approaches to teaching ear-training in music school. Participants were 423 pupils (60% female; Mage = 10.55 years, SDage = 0.92) in the third grade. In two ear-training lessons prepared either by the standard (STA) or the multimodal and interdisciplinary cognitive-emotional approach (CEA), pupils listened to a 2-minute excerpt from the 4th movement (Allegro con fuoco) of the Symphony no. 9 in E minor, Op. 95 ("From the New World") by Antonin Dvorak. The Geneva Emotional Music Scale (GEMS-9, Zentner et al., 2008) was translated and adapted to measure music-evoked emotions. Pupils also reported their music liking. In this study, the original three-factor structure of the GEMS-9 was not replicated, and instead a two-factor solution with factors labelled Activation and Calmness emerged. The results showed that in both groups the music evoked moderate to moderately high Activation and low Calmness. Pupils reported high music liking, however, those who participated in the CEA liked the music more than those who participated in the STA. The listening activities that enrich children's experiences of classical music in the classroom are discussed. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.31820/pt.32.1.5
JN  - Psihologijske Teme
VO  - 32
IP  - 1
PG  - 81-104
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.31820%2fpt.32.1.5

<82. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Relaxing effects of music and odors on physiological recovery after cognitive stress and unexpected absence of multisensory benefit. [References].
DP  - Jul 2023
YR  - 2023
LG  - English
AU  - Baccarani, Alessia
AU  - Donnadieu, Sophie
AU  - Pellissier, Sonia
AU  - Brochard, Renaud
SO  - Psychophysiology. Vol.60,(7), 2023, pp. 1-16.  ArtID e14251.
MO  - Jul
IS  - 0048-5772
IT  - 1469-8986
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Several studies have described, often separately, the relaxing effects of music or odor on the autonomic nervous system (ANS) activity. Only a few studies compared the presentation of these stimuli and their interaction within a same experimental protocol. Here, we examined whether relaxing music (slow-paced classical pieces) and odor (lavender essential oil) either presented in isolation or in combination would facilitate physiological recovery after cognitive stress. We continuously recorded the electrocardiogram to assess the high-frequency component of heart rate variability (HF-HRV), an index of parasympathetic activity, and electrodermal activity (EDA), an index of sympathetic activity, 10 min before, during and 30 min after a cognitive stress (i.e., completing timely constrained cognitively demanding tasks) in 99 participants allocated to four recovery conditions (control N = 26, music N = 23, odor N = 24, music+odor N = 26). The stressing event triggered both a significant increase in EDA and decrease in HF-HRV (compared to baseline). During the recovery period, the odor elicited a greater decrease in EDA compared to an odorless silent control, whereas no difference in HRV was observed. Conversely, during this period, music elicited a greater increase in HF-HRV compared to control whereas no difference in EDA was observed. Strikingly, in the multimodal music+odor condition, no beneficial effect was observed on ANS indexes 30 min after stress. Overall, our study confirms that both olfactory and musical stimuli have relaxing effects after stress on ANS when presented separately only, which might rely on distinct neural mechanisms and autonomic pathways. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1111/psyp.14251
JN  - Psychophysiology
VO  - 60
IP  - 7
PG  - 1-16
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1111%2fpsyp.14251

<83. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - An age-matched comparison of gait parameters in 180 degrees turning between community-dwelling adults and community-dwelling individuals with Parkinson's disease: A secondary analysis.DP  - 2023
YR  - 2023
LG  - English
AU  - Duran, Diego Alejandro F
SO  - Dissertation Abstracts International Section A: Humanities and Social Sciences. Vol.84,(10-A), 2023, pp. No Pagination Specified. 
IS  - 0419-4209
IB  - 979-8377650713
PT  - Dissertation Abstract
AB  - Background: Turning while ambulating is difficult for people with Parkinson's Disease (PD) and leads to falls. Limited interventions have targeted improving turning gait. Research conducted at Fresno State has documented changes in turning after multimodal intervention programs. Spring 2019 study utilized a multimodal intervention program whereas Fall 2019 used a multimodal intervention protocol with additional strengthening and music. Objective: Identify which intervention program had better outcomes and compare participant turning gait to norms. Methods: Two independent group experimental designs using secondary analysis of turning gait parameters (stance %, number of steps, step length, turn time and foot angle) from the measures of COGTUG and TUG. Paired t-test were performed for gait parameters of each data sample. Differences from each study were then compared to each other through 2 group t-tests. ANOVA was performed to compare intervention groups to norms. Results: Paired t-test showed significant p-values for turn time and stance percent for COGTUG of both studies. No significant 2 group t-tests. ANOVA identified significant differences between PD groups and norms. Discussion and Conclusion: No significant differences found between outcomes for PD intervention studies. Findings suggest multimodal intervention protocols had similar effect on turning gait mechanics with or without additional strengthening and music. Due to research limitations and small sample size more research is needed.  (PsycInfo Database Record (c) 2023 APA, all rights reserved)
JN  - Dissertation Abstracts International Section A: Humanities and Social Sciences
VO  - 84
IP  - 10-A
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&AN=2023-76633-025

<84. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Complementary and integrative medicine and eating disorders in youth: Traditional yoga, virtual reality, light therapy, neurofeedback, acupuncture, energy psychology techniques, art therapies, and spirituality. [References].
DP  - Apr 2023
YR  - 2023
LG  - English
AU  - Zakers, Aleema
AU  - Cimolai, Valentina
SO  - Child and Adolescent Psychiatric Clinics of North America. Vol.32,(2), 2023, pp. 421-450. 
MO  - Apr
IS  - 1056-4993
IT  - 1558-0490
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Eating disorders (EDs) are a non-heterogeneous group of illnesses with significant physical and mental comorbidity and mortality associated with maladaptive coping. With the exception of lisdexamfetamine (Vyvanse) for binge eating disorder, no medications have been effective for the core symptoms of ED. ED requires a multimodal approach. Complementary and integrative medicine (CIM) can be helpful as an adjunct. The most promising CIM interventions are traditional yoga, virtual reality, eye movement desensitization and reprocessing, Music Therapy, and biofeedback/neurofeedback. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1016/j.chc.2022.08.014
JN  - Child and Adolescent Psychiatric Clinics of North America
VO  - 32
IP  - 2
PG  - 421-450
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1016%2fj.chc.2022.08.014

<85. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - The interlinking of alpha waves and visuospatial cognition in motor-based domains. [References].
DP  - Jun 2023
YR  - 2023
LG  - English
AU  - Morrone, Jazmin
AU  - Minini, Loredana
SO  - Neuroscience and Biobehavioral Reviews. Vol.149, 2023, ArtID 105152.
MO  - Jun
IS  - 0149-7634
IT  - 1873-7528
PT  - Journal
PT  - Peer Reviewed Journal
AB  - The manner in which we perceive and respond in accordance to the world is encompassed by our ability to process multimodal input stimuli. In other words, in order to perform any task, especially at a high degree of proficiency, high dependence is placed upon our ability to interact with, interpret, and visualize input stimuli from our environment, known as visuospatial cognition (Chueh et al., 2017). This article will explore and encapsulate the importance of visuospatial cognition, in terms of the link it has with the performance of tasks in various fields, such as artistry, musical performance, and athleticism. Alpha wave investigation will be discussed as a means of both identifying and characterizing the degree of performance within these domains. Findings from this investigation may be used as a modality to optimize performance in the explored domains (e.g., with Neurofeedback techniques). The limitations of using Electroencephalography (EEG) to support the enhancement of this task performance and the recommendations to elicit further research, will also be explored. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1016/j.neubiorev.2023.105152
JN  - Neuroscience and Biobehavioral Reviews
VO  - 149
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1016%2fj.neubiorev.2023.105152

<86. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - A raciosemiotics of appropriation: Transnational performance of raciogender among Mexican K-Pop fans. [References].
DP  - Win, 2023
YR  - 2023
LG  - English
AU  - Yoo, Joyhanna
SO  - Signs and Society. Vol.11,(1), 2023, pp. 68-92. 
MO  - Win
IS  - 2326-4489
IT  - 2326-4497
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Advancing a raciosemiotics (Smalls 2020) of appropriation, this article examines what happens when raciolinguistically charged signs circulate and are taken up in a context different to their production. Based on face-to-face and digital ethnography of K-pop fans in Mexico, this study presents a multimodal semiotic analysis of fans' metapragmatic discourses and social media practices. I show how fans orient to the female K-pop idol, a mediatized figure of personhood (Agha 2005; Hiramoto and Kang 2017) indexical of hegemonic cosmopolitan femininity but simultaneously an exotic racialized Other in many non-Korean contexts. My examination of fan discourses and performance on social media treats the characterological figure of the female K-pop idol as a desirable, aspirational racial other for Mexican fans, while attending to the sociohistorical specificities of Asian racialization in the context of Mexico. The characterological figure is shaped by, and must interact with, local racial ideologies. My analysis suggests that such performances allow fans to differentiate themselves from other Mexican youth by demonstrating their knowledge of intra-Asian differences. Moreover, they are able to fashion neoliberal and queer subjectivities, albeit conditionally, through their indexical approximation of K-pop idols. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1086/722810
JN  - Signs and Society
VO  - 11
IP  - 1
PG  - 68-92
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1086%2f722810

<87. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Sampling as ethnographic method/remixing Gulu City. [References].
DP  - Mar 2023
YR  - 2023
LG  - English
AU  - Bitter, Joella
SO  - American Anthropologist. Vol.125,(1), 2023, pp. 23-35. 
MO  - Mar
IS  - 0002-7294
IT  - 1548-1433
PT  - Journal
PT  - Peer Reviewed Journal
AB  - This article describes the process of producing Gulu SoundTracks, a digital sonic ethnographic project accessible at gulusoundtracks.org, with four Ugandan music producers based in Gulu. The album comprises eight digital audio tracks that tell stories about Gulu musically through the compositional mixing of field soundscape recordings. Using field recordings as samples opened up sampling as a multimodal method for ethnographic storytelling which entails listening that is "vexed" (Weheliye 2005), archival, multiple, and generative. Pointing to insights from the project's creative process, the author explores sound praxis as a modality for amplifying fruitful connections between ethnographic and Afrodiasporic arts traditions. In conversation with others using sound methods in anthropology, ethnomusicology, and digital sound studies, this article stages a dialogue between sound-based work, critical treatments of Black and Afrosonic cultural production, and experimental ethnography. Sampling as method centers ethnographic imagination and points to critical possibilities field recording holds for anthropological knowledge production. (PsycInfo Database Record (c) 2023 APA, all rights reserved)

      Abstract (Spanish)
      Este articulo describe el proceso de producir Gulu SoundsTracks, un proyecto etnogra fico sonico digital accesible en gulusoundtracks.org, con cuatro productores de musica de Uganda localizados en Gulu. El album consta de ocho pistas de audio digitales que cuentan historias acerca de Gulu musicalmente a traves de la mezcla composicional de las grabaciones de sonidos de campo. El uso de grabaciones de campo como muestras abrio el muestreo como un metodo multimodal para la narracion de historias etnogra ficas el cual implica escuchar lo que es "controvertido" (Weheliye 2005) perdurable, multiple y generativo. Apuntando a entendimientos del proceso creativo del proyecto, el autor explora la practica de sonidos como una modalidad para amplificar conex iones fructiferas entre la etnografia y las tradiciones artisticas afrodiasporicas. En conversacion con otros usando metodos de sonido en antropologia, etnomusicologia y estudios de sonido digital, este articulo organiza un dialogo entre trabajo basado en sonido, tratamientos criticos a la produccion cultural negra y afrosonica, y la etnografia experimental. El muestreo como metodo centra la imaginacion etnografica y senala las posibilidades criticas que la grabacion de campo sostiene para la produccion de conocimiento antropologico. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1111/aman.13804
JN  - American Anthropologist
VO  - 125
IP  - 1
PG  - 23-35
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1111%2faman.13804

<88. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Work in process: Expressive arts therapy solutions for EMDR therapists. [References].
DP  - 2023
YR  - 2023
LG  - English
AU  - Rodriguez, Irene
AU  - Marich, Jamie
SO  - Davis, Elizabeth [Ed]; Fitzgerald, Jocelyn [Ed]; Jacobs, Sherri [Ed]; Marchand, Jennifer [Ed]. (2023). EMDR and creative arts therapies. (pp. 320-341). x, 350pp. New York, NY, US: Routledge; US. 
IB  - 9780367742850 (Hardcover); 978-1-003-15693-2 (Digital (undefined format)); 978-0-367-74283-6 (Paperback)
PT  - Book
PT  - Edited Book
AB  - This chapter emphasizes the power of process in the healing journey using the expressive arts therapy as a multi-modal approach. It offers resources and applications for Eye Movement Desensitization and Reprocessing (EMDR) therapists seeking to work with complex trauma and dissociation in a more embodied and expressive way, including through dance/movement, visual arts, writing, drama, and music. The chapter empower therapists and their clients to explore expressive possibilities that can help them overcome therapeutic blocks. It presents four case studies alongside practical skills that EMDR therapists can implement in their work with clients. The chapter also presents culturally adaptive approaches especially with Spanish-speaking populations. It gives general best practices of how expressive arts practices and processes can be integrated into all eight phases. While EMDR therapy is one of the most important innovations in the history of modern psychotherapy, the existence of books like this one shows that the technical protocol may not be enough for working with many clients. The two practices-expressive arts therapy and EMDR therapy-can work together and shows how blending of the modalities will continue to occur as EMDR therapists feel a greater sense of empowerment to be more innovative. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
PG  - 320-341
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&AN=2023-29431-011

<89. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Image is all for music retrieval: Interactive music retrieval system using images with mood and theme attributes. [References].
DP  - Apr 22, 2023
YR  - 2023
AU  - Park, Jeongeun
AU  - Kim, Minchae
AU  - Kim, Ha Young
SO  - International Journal of Human-Computer Interaction. 2023, pp. No Pagination Specified. 
MO  - Apr
IS  - 1044-7318
IT  - 1532-7590
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Abstract We propose an intuitive image-to-music retrieval (IMR) framework to improve the user experience on these platforms. The proposed method extracts mood and theme tags by searching for images from a pre-built database that are similar to a query image and then retrieves music with matching tag information. We investigated the system's effectiveness by comparing participants' satisfaction, intention to use, and valence between those who interacted with the system and those who did not. We also examined whether using mood or theme attributes affected the user-perceived suitability of the retrieved music. Results showed that all three variables of the interaction group were significantly higher than that of the non-interaction group and that there was no difference in the perceived suitability of music between the mood and theme attributes. Our study concludes that image attributes are effective in successful music retrieval and that interaction is a crucial factor in designing IMR systems. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1080/10447318.2023.2201557
JN  - International Journal of Human-Computer Interaction
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1080%2f10447318.2023.2201557

<90. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - The Routledge handbook of semiosis and the brain. [References].
DP  - 2023
YR  - 2023
LG  - English
AU  - Garcia, Adolfo M [Ed]
AU  - Ibanez, Agustin [Ed]
SO  - (2023). The Routledge handbook of semiosis and the brain. xviii, 412pp. New York, NY, US: Routledge; US. 
IB  - 9780367509163 (Hardcover); 9781003051817 (Digital (undefined format)); 9781032355610 (Paperback)
PT  - Book
PT  - Edited Book
AB  - The human organism is typified by an unyielding drive towards sensemaking. Anchored in the humanities, classical semiotics first studied this phenomenon focusing on sign properties (e.g., indication, reference, symbolism, analogy, metaphor), with later perspectives tracing links among signs, body processes, and cultural niches in interpersonal communication. More recently, new insights have stemmed from the natural sciences, including predominantly biological approaches, such as biosemiotics, alongside contributions from neuropsychology, the behavioral sciences, and social cognitive and affective neuroscience. Nevertheless, integrative efforts across cultural and biological traditions have been preliminary at best, failing to track the convergences of the neurological, cognitive, sensorimotor, visceral, perceptual, and social processes that jointly shape our individual and social semiotic experiences. This book introduces neurosemiotics, a pluralistic framework to reconsider semiosis as an emergent phenomenon at the interface of biology and culture. Across individual and interpersonal settings, meaning and communication are influenced by external and internal processes bridging phenomenological and biological dimensions. Yet, each of these dyads has been segregated into discipline-specific topics, with attempts to chart their intersections proving preliminary at best. Bringing together perspectives from world-leading experts, the book seeks to overcome these disciplinary divides at both the empirical and theoretical levels. Its various chapters chart the foundations of neurosemiotics; characterize linguistic and interpersonal dynamics as shaped by neurocognitive, bodily, situational, and societal factors; and examine other daily neurosemiotic occurrences driven by faces, music, tools, and even visceral signals. This book is a state-of-the-art resource for students and researchers interested in how humans and other animals construe meaningful experience, informing such fields as cognitive neuroscience, biosemiotics, philosophy of mind, neuropsychology, neurolinguistics, and evolutionary biology. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.4324/9781003051817
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.4324%2f9781003051817

<91. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Future perspectives and challenges. [References].
DP  - 2023
YR  - 2023
LG  - English
AU  - Eerola, Tuomas
SO  - Kussner, Mats B [Ed]; Taruffi, Liila [Ed]; Floridou, Georgia A [Ed]. (2023). Music and mental imagery. (pp. 281-288). xxiii, 293pp. New York, NY, US: Routledge; US. 
IB  - 9780367352165 (Hardcover); 978-1-032-37607-3 (Paperback); 978-0-429-33007-0 (Digital (undefined format))
PT  - Book
PT  - Edited Book
AB  - This chapter addresses the issues of defining and capturing mental imagery in its different varieties (e.g., visual, auditory, kinaesthetic, and multimodal), and outlines perspectives, particularly that of embodied cognition, that might be helpful in bringing some separate threads together and prioritizes the list of challenges that need to be tackled before a coherent research programme is articulated. Diverse sets of methods in empirical research have been wielded towards music-related mental imagery; from first-person accounts to structured interviews and surveys to self-report evaluation tasks in experiments using rating scales as well as reaction time tasks. Music-related mental imagery research itself has not been very active in proposing new theories of its own, since it has inherited a host of eminent theories from other mental imagery research, mainly from psychology and linguistics, as well as research on memory and learning. Moreover, the trend of connecting specific aspects of mental imagery into broader cognitive processing such as mind-wandering, attention, or multimodal and cross-modal processing seems to be challenging. It is crucial to capture musical imagery and other types of mental imagery related to music-making and listening in a way that is precise, both in qualitative terms but also as a temporal process. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
PG  - 281-288
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&AN=2023-28146-024

<92. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Multimodal perception in selected visually impaired pianists: Towards a conceptual framework. [References].
DP  - 2023
YR  - 2023
LG  - English
AU  - Herbst, Anri
AU  - van Zyl, Silvia
SO  - Kussner, Mats B [Ed]; Taruffi, Liila [Ed]; Floridou, Georgia A [Ed]. (2023). Music and mental imagery. (pp. 255-267). xxiii, 293pp. New York, NY, US: Routledge; US. 
IB  - 9780367352165 (Hardcover); 978-1-032-37607-3 (Paperback); 978-0-429-33007-0 (Digital (undefined format))
PT  - Book
PT  - Edited Book
AB  - Approaching the study from within a bio-psycho-social context, this chapter views visually impaired (VI) pianists as musicians who navigate their internal and external environments to function in a performance-oriented sonic world. It investigates a small cohort of VI South African pianists in search of emergent themes with regard to the phenomenon of mental imagery, which we viewed through the lens of relevant cognitive-based literature and applied principles of embodied cognition theory (ECT) and dynamic systems theory (DST). The chapter presents a conceptual framework that consolidates the emergent themes from the qualitative findings with relevant cognitive-based literature and supporting theories. ECT explains the cyclical brain processes that shape human perception. The emergent themes from the qualitative study in combination with cognitive-based literature and applied principles of DST and ECT culminate in the proposed conceptual framework. Analysis of audio-visual transcriptions employed grounded theory with initial and axial manual coding. Six themes reflecting participants' responses emerged from the data analysis. These themes include complexity of braille notation; focus on music theoretical aspects of a work; use of metaphor; use of non-visual modalities; experiences of affect; and mind-wandering. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
PG  - 255-267
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&AN=2023-28146-022

<93. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Imagery and movement in music-based rehabilitation and music pedagogy. [References].
DP  - 2023
YR  - 2023
LG  - English
AU  - Schaefer, Rebecca S
SO  - Kussner, Mats B [Ed]; Taruffi, Liila [Ed]; Floridou, Georgia A [Ed]. (2023). Music and mental imagery. (pp. 211-220). xxiii, 293pp. New York, NY, US: Routledge; US. 
IB  - 9780367352165 (Hardcover); 978-1-032-37607-3 (Paperback); 978-0-429-33007-0 (Digital (undefined format))
PT  - Book
PT  - Edited Book
AB  - The current chapter focuses specifically on how imagery can support movement and movement learning. To this end, two main application areas will be considered: movement rehabilitation and music pedagogy. While the functional goals in these two domains are very different (i.e., to recover "normal" movement function vs. to attain highly skilled, specialized movement), both processes arguably rely on learning mechanisms that support motor skill acquisition (Maier et al., 2019; Sampaio-Baptista et al., 2018). Both thus likely involve forming new or renewed movement representations in the motor system of the brain, implemented by developing novel learning-related neural connections. In both cases, repetition and the salience of the movement experience, among others, are good predictors of movement acquisition (e.g., Kleim & Jones, 2008; Korman et al., 003). Although studies are sparse, there are indications that methods using mental imagery represent a low-cost, adaptable way to support movement learning as well as music pedagogy, albeit using different elements of imagery (i.e., through its time structure when cueing movement, vs. the association with an emotional quality for expressivity, or multimodal integration for reduced cognitive load). The use of mental imagery for motor learning is considered, focusing first on how music imagery might replace or support the use of auditory cues in rehabilitation, followed by how other aspects of imagery are used in music pedagogy. Taken together, music imagery abilities may be useful for movement recovery, and more generalized imagery techniques may support musical skill acquisition and performance. While many of these concepts still need scientific support to be further developed into broadly applicable protocols and teaching methods, the observation that many clinicians and teachers are already intuitively using these approaches is striking. Future research focusing on refining our understanding of the different types of imagery, the range of individual differences in imagery abilities, and the predictors of these differences, offers to yield a wide variety of applications in both movement rehabilitation and music pedagogy. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
PG  - 211-220
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&AN=2023-28146-018

<94. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Musical daydreaming and kinds of consciousness. [References].
DP  - 2023
YR  - 2023
LG  - English
AU  - Herbert, Ruth
SO  - Kussner, Mats B [Ed]; Taruffi, Liila [Ed]; Floridou, Georgia A [Ed]. (2023). Music and mental imagery. (pp. 167-177). xxiii, 293pp. New York, NY, US: Routledge; US. 
IB  - 9780367352165 (Hardcover); 978-1-032-37607-3 (Paperback); 978-0-429-33007-0 (Digital (undefined format))
PT  - Book
PT  - Edited Book
AB  - This chapter examines first-hand reports of subjective experiences of listening to music accumulated over more than a decade, from several UK-based research projects centring on the phenomenology of everyday music listening. It considers definitions of music-evoked mind-wandering and musical daydreaming, and explains the adoption of the latter term. The chapter explores emergent characteristics of musical daydreaming episodes apparent in verbal and written reports of subjective music-listening experiences, including sequential versus fragmented experience; absorption, and detachment; repetitive daydreams; perceiver perspective; multimodal experience; age-related differences in content and structure of experiences. It provides examples to conceptualizations of kinds of consciousness to phenomenological properties of non-musical mind-wandering/daydreaming identified in cognitive psychological literature. Musical daydreams reflect a heteronomous, multimodal model of listening, sometimes called "hearing as": subjective experience is informed by extramusical factors, including socio-cultural sources and autobiographical memories and aspects of external environment. Chronobiological understanding of musical experience remains speculative, but the hypothesis that musical daydreaming may function as a self-regulatory process affording respite from the vicissitudes of daily life-a space for simply "being"-merits further exploration. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
PG  - 167-177
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&AN=2023-28146-014

<95. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Music and multimodal mental imagery. [References].
DP  - 2023
YR  - 2023
LG  - English
AU  - Nanay, Bence
SO  - Kussner, Mats B [Ed]; Taruffi, Liila [Ed]; Floridou, Georgia A [Ed]. (2023). Music and mental imagery. (pp. 64-73). xxiii, 293pp. New York, NY, US: Routledge; US. 
IB  - 9780367352165 (Hardcover); 978-1-032-37607-3 (Paperback); 978-0-429-33007-0 (Digital (undefined format))
PT  - Book
PT  - Edited Book
AB  - This chapter outlines a fairly wide conception of mental imagery, which is very close to how psychologists and neuroscientists use this concept and zero in on an important, but thus far relatively unexplored form of mental imagery, called multimodal mental imagery. It highlights the importance of auditory mental imagery in listening to music, and argues that multimodal mental imagery also plays a crucial role in listening to music. A lot of research has focused on how the emotional salience of the visual input influences the perception of music. Pulling together philosophy, psychology, and neuroscience, the chapter also argues that multimodal mental imagery plays a crucial role in the engagement with musical works. Expectations play a crucial role in the engagement with music (and art in general). Many of the expectations are fairly indeterminate: when people are listening to a musical piece they have never heard before, they will still have some expectations of how a tune will continue, but they do not know what exactly will happen. In discussing music, the chapter focuses on the interplay between the auditory and the visual sense modalities. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
PG  - 64-73
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&AN=2023-28146-005

<96. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Music and mental imagery. [References].
DP  - 2023
YR  - 2023
LG  - English
AU  - Kussner, Mats B [Ed]
AU  - Taruffi, Liila [Ed]
AU  - Floridou, Georgia A [Ed]
SO  - (2023). Music and mental imagery. xxiii, 293pp. New York, NY, US: Routledge; US. 
IB  - 9780367352165 (Hardcover); 978-1-032-37607-3 (Paperback); 978-0-429-33007-0 (Digital (undefined format))
PT  - Book
PT  - Edited Book
AB  - Mental imagery (MI) is a rich internal experience, which can comprise several modalities, most commonly visual, motor, and auditory domains. It can be experienced spontaneously or deliberately, can be neutral or emotional, and can be helpful or confounding to an ongoing task. All of these characteristics and more are often experienced as a reaction to hearing, performing, remembering, or composing music. Drawing on perspectives from music psychology, cognitive neuroscience, philosophy, musicology, clinical psychology, and music education, this book provides a critical overview of cutting-edge research on the various types of mental imagery associated with music. The four main parts cover an introduction to the different types of mental imagery associated with music such as auditory/musical, visual, kinaesthetic, and multimodal mental imagery; a critical assessment of established and novel ways to measure mental imagery in various musical contexts; coverage of different states of consciousness, all of which are relevant for, and often associated with, mental imagery in music, and a critical overview of applications of mental imagery in health, educational, and performance settings. By both critically reviewing up-to-date scientific research and offering new empirical results, the book provides a unique overview of the different types and origins of mental imagery in musical contexts, various ways to measure them, and intriguing insights into related mental phenomena such as mind-wandering and synaesthesia. This will be of particular interest for scholars and researchers of music psychology and music education. It will also be useful for practitioners working with music in applied health and educational contexts. The book's main goal is to bring together-and critically discuss-theoretical and empirical work on mental imagery associated with, or related to, music, and develop potential avenues for future collaborative work where each participating discipline gives and gains something. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.4324/9780429330070
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.4324%2f9780429330070

<97. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Decoding mental states after severe brain injury.DP  - 2023
YR  - 2023
LG  - English
AU  - Gibson, Raechelle M
SO  - Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.84,(3-B), 2023, pp. No Pagination Specified. 
IS  - 0419-4217
IB  - 979-8845473172
PT  - Dissertation Abstract
AB  - Some patients with disorders of consciousness retain sensory and cognitive abilities that are not apparent from their outward behaviour. It is crucial to identify and characterise these covert abilities for diagnosis, prognosis, and medical ethics. This thesis uses neuroimaging techniques to investigate cognitive preservation and awareness in patients who are behaviourally non-responsive due to acquired brain injuries. In the first chapter, a large sample of healthy volunteers, including experienced athletes and musicians, imagined actions of varying complexity and familiarity. Motor imagery involving certain complex, familiar actions correlated with a more robust sensorimotor rhythm. In the second chapter, several patients with disorders of consciousness participated in multiple experiments based on neural responses to mental imagery, including one task featuring complex, familiar imagined actions. Although the patients did not generate enhanced sensorimotor rhythms for the complex, familiar motor imagery, the detection of covert cognition was more sensitive owing to the multi-modal nature of the assessment. In the final empirical chapter, a sample of healthy volunteers and a heterogeneous cohort of patients with disorders of consciousness completed a novel oddball task based on tactile stimulation. Critically, this task delineated an attentional hierarchy in the patient sample, and patients with the ability to follow commands were differentiated from those unable to do so by event-related potential evidence of attentional orienting. Due to the heterogeneity of aetiology and pathology in the disorders of consciousness, these patients vary in their suitability for neuroimaging, the preservation of neural structures, and the cognitive resources available to them. Assessments of several perceptual and cognitive abilities supported by spatially-distinct brain regions and indexed by multiple neural signatures are therefore required to accurately characterise a patient's abilities and probable subjective experience. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
JN  - Dissertation Abstracts International: Section B: The Sciences and Engineering
VO  - 84
IP  - 3-B
PG  - No Pagination Specified
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&AN=2023-10936-207

<98. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Playing through an expressive lens. [References].
DP  - 2023
YR  - 2023
LG  - English
AU  - Turner, Renee
SO  - Malchiodi, Cathy A [Ed]. (2023). Handbook of expressive arts therapy. (pp. 155-169). xviii, 334pp. New York, NY, US: The Guilford Press; US. 
IB  - 9781462550524 (Paperback); 9781462550531 (Hardcover)
PT  - Book
PT  - Edited Book
AB  - Play is the cornerstone of human development, establishing the early foundation for imagination, connection, and social understanding. During the process of natural play, children connect to a sense of wonder and creativity, experience joy and relaxation, and build internal resources as they explore the world around them. Play therapy is the intentional pairing of a developmentally matched medium with a therapeutic relationship through which children play out their experiences and express their thoughts and emotions. Play therapy provides fun, symbolic expression, catharsis, social development, mastery, and release of energy. This chapter helps the clinicians to recognize the complementary nature of play therapy alongside other expressive therapies using the Expressive Therapies Continuum (ETC) as a framework for integrative and multimodal practice. Play therapists are encouraged to incorporate expressive therapies into their existing theoretical frameworks in order to better serve their clients' needs. Play therapists can gain a better understanding of when and how expressive therapies should be used by doing this. When working with young children, it is also hoped that expressive therapists from more conventional modalities like art, drama, and music will see the value in incorporating play-based expressive techniques into their current practice. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
PG  - 155-169
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&AN=2023-07868-009

<99. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - "It's cleaner, definitely": Collaborative process in audio production. [References].
DP  - Sep 2023
YR  - 2023
LG  - English
AU  - Deacon, Thomas
AU  - Healey, Patrick
AU  - Barthet, Mathieu
SO  - Computer Supported Cooperative Work (CSCW). Vol.32,(3), 2023, pp. 475-505. 
MO  - Sep
IS  - 0925-9724
IT  - 1573-7551
PT  - Journal
PT  - Peer Reviewed Journal
AB  - Working from vague client instructions, how do audio producers collaborate to diagnose what specifically is wrong with a piece of music, where the problem is and what to do about it? This paper presents a design ethnography that uncovers some of the ways in which two music producers co-ordinate their understanding of complex representations of pieces of music while working together in a studio. Our analysis shows that audio producers constantly make judgements based on audio and visual evidence while working with complex digital tools, which can lead to ambiguity in assessments of issues. We show how multimodal conduct guides the process of work and that complex media objects are integrated as elements of interaction by the music producers. The findings provide an understanding how people currently collaborate when producing audio, to support the design of better tools and systems for collaborative audio production in the future. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
DO  - https://dx.doi.org/10.1007/s10606-022-09448-1
JN  - Computer Supported Cooperative Work (CSCW)
VO  - 32
IP  - 3
PG  - 475-505
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc21&DO=10.1007%2fs10606-022-09448-1

<100. >
VN  - Ovid Technologies
DB  - APA PsycInfo
TI  - Multimodal recognition of emotions in music and language. [References].
DP  - Jan 2022
YR  - 2022
LG  - English
AU  - Proverbio, Alice Mado
AU  - Russo, Francesca
SO  - Psychology of Music. Vol.50,(1), 2022, pp. 54-68. 
MO  - Jan
IS  - 0305-7356
IT  - 1741-3087
PT  - Journal
PT  - Peer Reviewed Journal
AB  - We investigated through electrophysiological recordings how music-induced emotions are recognized and combined with the emotional content of written sentences. Twenty-four sad, joyful, and frightening musical tracks were presented to 16 participants reading 270 short sentences conveying a sad, joyful, or frightening emotional meaning. Audiovisual stimuli could be emotionally congruent or incongruent with each other; participants were asked to pay attention and respond to filler sentences containing cities' names, while ignoring the rest. The amplitude values of event-related potentials (ERPs) were subjected to repeated measures ANOVAs. Distinct electrophysiological markers were identified for the processing of stimuli inducing fear (N450, either linguistic or musical), for language-induced sadness (P300) and for joyful music (positive P2 and LP potentials). The music/language emotional discordance elicited a large N400 mismatch response (p = .032). Its stronger intracranial source was the right superior temporal gyrus (STG) devoted to multisensory integration of emotions. The results suggest that music can communicate emotional meaning as distinctively as language. (PsycInfo Database Record (c) 2024 APA, all rights reserved)
DO  - https://dx.doi.org/10.1177/0305735620978697
JN  - Psychology of Music
VO  - 50
IP  - 1
PG  - 54-68
XL  - https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1177%2f0305735620978697



